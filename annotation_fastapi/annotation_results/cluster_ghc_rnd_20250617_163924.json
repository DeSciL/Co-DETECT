{
  "suggestions": {
    "edge_case_0": "when the post targets non-protected groups, individuals, or characteristics (e.g., political groups, institutions, public figures) without explicit calls for violence or slurs targeting protected groups -> classify as 0 (no hate speech)",
    "edge_case_1": "when the post references protected groups but lacks explicit assaults on dignity, calls for violence, or vulgarity/offensive language directed at them -> classify as 0 (no hate speech)",
    "edge_case_2": "when the post contains references to violence, threats, or aggressive language without inciting harm against protected groups or using explicit hate speech elements -> classify as 0 (no hate speech)",
    "edge_case_3": "when the post uses implicit antagonism, generalizations, or ambiguous framing without explicit demeaning language, calls for violence, or offensive targeting of protected groups -> classify as 0 (no hate speech)",
    "edge_case_4": "when content lacks sufficient information for evaluation (e.g., URLs, non-text media, ambiguous language, or insufficient context) -> refuse to classify (-1)",
    "edge_case_5": "when ambiguous/coded references to protected groups lack explicit demeaning language, calls for violence, or clarifying context -> classify as no hate speech (0) but flag for review",
    "edge_case_6": "when a post dehumanizes protected groups by invalidating identities or trivializing atrocities through symbolism/narratives -> classify as hate speech (1)",
    "edge_case_7": "when content reports offensive material or uses insensitive language without direct targeting of protected groups -> classify as no hate speech (0) but flag for review/insensitivity",
    "edge_case_8": "when content lacks explicit evidence of demeaning language, calls for violence, or offensive slurs targeting protected characteristics, despite potential ambiguity, sarcasm, indirect references, or coded language -> classify as 0 (no hate speech) with low confidence due to ambiguity"
  },
  "improvement_clusters": [
    {
      "text_to_annotate": "Iâ€™m not sure if this is a place to post this, but I need genuine advice. A friend got super involved with SJWs and now theyâ€™re suddenly claiming theyâ€™re trans, something they never even hinted at before. I donâ€™t know what to do because I have a feeling theyâ€™re doing it to fit in. ",
      "uid": "ec71beb1-a3dd-4881-bb88-901feae0a560",
      "edge_case_id": 6.0,
      "pca_x": 0.01927229138966785,
      "pca_y": -0.17690256991324751,
      "raw_annotations": "{\n  \"analysis\": \"1. Assaults on Human Dignity: This criterion checks for demeaning or degrading language toward individuals or groups based on protected characteristics. The post refers to 'SJWs' (Social Justice Warriors) in a somewhat dismissive tone, but the main focus is on the friend's claim of being trans. The phrase 'claiming they're trans, something they never even hinted at before' and 'I have a feeling they're doing it to fit in' implies skepticism about the authenticity of the friend's trans identity. This can be interpreted as questioning or invalidating someone's gender identity, which may be considered demeaning to trans individuals. However, the post does not use explicit slurs or overtly degrading language, but the implication is that being trans is a trend or a choice to 'fit in,' which can be seen as undermining the legitimacy of trans identities. \\n\\n2. Calls for Violence: There is no evidence in the text of any incitement or encouragement of physical harm or violence against any individual or group. No language in the post suggests or encourages violence. \\n\\n3. Vulgarity and/or Offensive Language: The post does not contain profanity or explicit slurs. The term 'SJWs' is sometimes used pejoratively, but in this context, it is not accompanied by offensive language. The skepticism toward the friend's trans identity is not expressed with vulgarity, but the implication may be offensive to some readers, particularly trans individuals, as it questions the authenticity of their identity.\",\n  \"annotation\": \"1\",\n  \"confidence\": 80,\n  \"new_edge_case\": true,\n  \"new_edge_case_rule\": \"When a post questions or invalidates the authenticity of a protected characteristic (e.g., gender identity) without using explicit slurs or vulgarity, but implies the identity is a trend or not genuine -> classify as hate speech (1)\"\n}",
      "analyses": "1. Assaults on Human Dignity: This criterion checks for demeaning or degrading language toward individuals or groups based on protected characteristics. The post refers to 'SJWs' (Social Justice Warriors) in a somewhat dismissive tone, but the main focus is on the friend's claim of being trans. The phrase 'claiming they're trans, something they never even hinted at before' and 'I have a feeling they're doing it to fit in' implies skepticism about the authenticity of the friend's trans identity. This can be interpreted as questioning or invalidating someone's gender identity, which may be considered demeaning to trans individuals. However, the post does not use explicit slurs or overtly degrading language, but the implication is that being trans is a trend or a choice to 'fit in,' which can be seen as undermining the legitimacy of trans identities. \n\n2. Calls for Violence: There is no evidence in the text of any incitement or encouragement of physical harm or violence against any individual or group. No language in the post suggests or encourages violence. \n\n3. Vulgarity and/or Offensive Language: The post does not contain profanity or explicit slurs. The term 'SJWs' is sometimes used pejoratively, but in this context, it is not accompanied by offensive language. The skepticism toward the friend's trans identity is not expressed with vulgarity, but the implication may be offensive to some readers, particularly trans individuals, as it questions the authenticity of their identity.",
      "annotation": 1,
      "confidence": 80,
      "guideline_improvement": "when a post dehumanizes protected groups by invalidating identities or trivializing atrocities through symbolism/narratives -> classify as hate speech (1)"
    },
    {
      "text_to_annotate": "ðŸŒ» DEFEND ðŸŒ» EUROPA ðŸŒ»",
      "uid": "6373e43e-62c7-4c27-9dbc-2815dd2ce5c1",
      "edge_case_id": 8.0,
      "pca_x": 0.04982951340465824,
      "pca_y": 0.2934124388661544,
      "raw_annotations": "{\n  \"analysis\": \"Step-by-step evaluation of ALL guideline criteria with text evidence:\\n\\n1. Assaults on Human Dignity: \\n- Guideline: Does the post demean or degrade individuals or groups based on race, ethnicity, gender, religion, sexual orientation, or other protected characteristics?\\n- Evaluation: The post says 'DEFEND EUROPA' with sunflower emojis. There is no explicit mention of any group, individual, or protected characteristic. The phrase 'DEFEND EUROPA' could, in some contexts, be associated with far-right or ethno-nationalist movements, but in isolation, without further context or explicit language, it does not directly demean or degrade any group.\\n- Satisfied: NOT SATISFIED (no explicit demeaning or degrading language present).\\n\\n2. Calls for Violence:\\n- Guideline: Does the post incite or encourage physical harm or violence against individuals or groups?\\n- Evaluation: The post does not contain any language that incites or encourages violence. The word 'DEFEND' could, in some contexts, imply a call to action, but there is no explicit or implicit call for violence in the text as presented.\\n- Satisfied: NOT SATISFIED (no call for violence present).\\n\\n3. Vulgarity and/or Offensive Language:\\n- Guideline: Does the post contain profanity, slurs, or other offensive language that may or may not be directed at individuals or groups?\\n- Evaluation: The post contains no profanity, slurs, or offensive language. The phrase and emojis are neutral in tone.\\n- Satisfied: NOT SATISFIED (no vulgar or offensive language present).\\n\\nConclusion: The post does not satisfy any of the hate speech criteria as defined in the guidelines. However, the phrase 'DEFEND EUROPA' can be a dog whistle or coded language in certain extremist contexts, but the guidelines do not specify how to handle ambiguous or coded language without explicit evidence.\",\n  \"annotation\": \"0\",\n  \"confidence\": 70,\n  \"new_edge_case\": true,\n  \"new_edge_case_rule\": \"When a phrase is potentially a coded reference to hate speech but lacks explicit evidence or context per the guidelines -> classify as 0 (no hate speech) with low confidence\"\n}",
      "analyses": "Step-by-step evaluation of ALL guideline criteria with text evidence:\n\n1. Assaults on Human Dignity: \n- Guideline: Does the post demean or degrade individuals or groups based on race, ethnicity, gender, religion, sexual orientation, or other protected characteristics?\n- Evaluation: The post says 'DEFEND EUROPA' with sunflower emojis. There is no explicit mention of any group, individual, or protected characteristic. The phrase 'DEFEND EUROPA' could, in some contexts, be associated with far-right or ethno-nationalist movements, but in isolation, without further context or explicit language, it does not directly demean or degrade any group.\n- Satisfied: NOT SATISFIED (no explicit demeaning or degrading language present).\n\n2. Calls for Violence:\n- Guideline: Does the post incite or encourage physical harm or violence against individuals or groups?\n- Evaluation: The post does not contain any language that incites or encourages violence. The word 'DEFEND' could, in some contexts, imply a call to action, but there is no explicit or implicit call for violence in the text as presented.\n- Satisfied: NOT SATISFIED (no call for violence present).\n\n3. Vulgarity and/or Offensive Language:\n- Guideline: Does the post contain profanity, slurs, or other offensive language that may or may not be directed at individuals or groups?\n- Evaluation: The post contains no profanity, slurs, or offensive language. The phrase and emojis are neutral in tone.\n- Satisfied: NOT SATISFIED (no vulgar or offensive language present).\n\nConclusion: The post does not satisfy any of the hate speech criteria as defined in the guidelines. However, the phrase 'DEFEND EUROPA' can be a dog whistle or coded language in certain extremist contexts, but the guidelines do not specify how to handle ambiguous or coded language without explicit evidence.",
      "annotation": 0,
      "confidence": 70,
      "guideline_improvement": "when content lacks explicit evidence of demeaning language, calls for violence, or offensive slurs targeting protected characteristics, despite potential ambiguity, sarcasm, indirect references, or coded language -> classify as 0 (no hate speech) with low confidence due to ambiguity"
    },
    {
      "text_to_annotate": "Establishment & Gov't riddled with kiddy fiddlers & #bbcnews are having a wankfest over #ABBA ",
      "uid": "50018554-6564-4bc1-86a8-743bbcdb3497",
      "edge_case_id": 0.0,
      "pca_x": 0.22861162395030798,
      "pca_y": -0.15293434762280267,
      "raw_annotations": "{\n  \"analysis\": \"1. Assaults on Human Dignity: The post uses the phrase 'kiddy fiddlers' to refer to members of the 'Establishment & Gov't.' 'Kiddy fiddler' is a slang term for a pedophile, which is a highly derogatory and demeaning accusation. However, it is directed at a broad, non-specific group (Establishment & Gov't), not a protected characteristic such as race, gender, etc. Therefore, this criterion is not strictly satisfied as per the guideline's focus on protected characteristics. 2. Calls for Violence: There is no explicit or implicit incitement or encouragement of physical harm or violence against any individual or group in the post. 3. Vulgarity and/or Offensive Language: The post contains vulgar and offensive language, specifically 'kiddy fiddlers' (a slur for pedophile) and 'wankfest' (a vulgar term). These terms are used in a derogatory and offensive manner, though not directly as hate speech against a protected group, but as general insults and vulgarity.\",\n  \"annotation\": \"0\",\n  \"confidence\": 70,\n  \"new_edge_case\": true,\n  \"new_edge_case_rule\": \"When vulgar or offensive language is used to insult or demean non-protected groups or institutions, but not based on protected characteristics, and there is no call for violence -> classify as 0 (no hate speech)\"\n}",
      "analyses": "1. Assaults on Human Dignity: The post uses the phrase 'kiddy fiddlers' to refer to members of the 'Establishment & Gov't.' 'Kiddy fiddler' is a slang term for a pedophile, which is a highly derogatory and demeaning accusation. However, it is directed at a broad, non-specific group (Establishment & Gov't), not a protected characteristic such as race, gender, etc. Therefore, this criterion is not strictly satisfied as per the guideline's focus on protected characteristics. 2. Calls for Violence: There is no explicit or implicit incitement or encouragement of physical harm or violence against any individual or group in the post. 3. Vulgarity and/or Offensive Language: The post contains vulgar and offensive language, specifically 'kiddy fiddlers' (a slur for pedophile) and 'wankfest' (a vulgar term). These terms are used in a derogatory and offensive manner, though not directly as hate speech against a protected group, but as general insults and vulgarity.",
      "annotation": 0,
      "confidence": 70,
      "guideline_improvement": "when the post targets non-protected groups, individuals, or characteristics (e.g., political groups, institutions, public figures) without explicit calls for violence or slurs targeting protected groups -> classify as 0 (no hate speech)"
    },
    {
      "text_to_annotate": "Jesus is the final solution. ",
      "uid": "003baeaf-62d5-43df-a75c-c69487aa8f8b",
      "edge_case_id": 4.0,
      "pca_x": -0.27574717659764547,
      "pca_y": 0.12274415478014239,
      "raw_annotations": "{\n  \"analysis\": \"1. Assaults on Human Dignity: Checking if the post demeans or degrades individuals or groups based on protected characteristics. The phrase 'Jesus is the final solution' does not explicitly mention or target any group or individual based on race, ethnicity, gender, religion, sexual orientation, or other protected characteristics. There is no direct evidence of demeaning or degrading language. \\n\\n2. Calls for Violence: Checking for incitement or encouragement of physical harm or violence. The phrase does not explicitly call for violence or harm against any individual or group. \\n\\n3. Vulgarity and/or Offensive Language: Checking for profanity, slurs, or other offensive language. The phrase does not contain profanity or slurs. However, the phrase 'final solution' is historically associated with the Holocaust and genocide, which could be interpreted as offensive or as a dog whistle in certain contexts. In this post, it is paired with 'Jesus,' which could be interpreted as a religious statement or as a coded reference. However, without further context, it is ambiguous whether the phrase is being used in a hateful or offensive manner, or simply as a religious assertion.\",\n  \"annotation\": \"-1\",\n  \"confidence\": 60,\n  \"new_edge_case\": true,\n  \"new_edge_case_rule\": \"When a phrase contains historically loaded or potentially hateful language (e.g., 'final solution') but lacks explicit targeting or context to determine intent -> refuse to classify (-1)\"\n}",
      "analyses": "1. Assaults on Human Dignity: Checking if the post demeans or degrades individuals or groups based on protected characteristics. The phrase 'Jesus is the final solution' does not explicitly mention or target any group or individual based on race, ethnicity, gender, religion, sexual orientation, or other protected characteristics. There is no direct evidence of demeaning or degrading language. \n\n2. Calls for Violence: Checking for incitement or encouragement of physical harm or violence. The phrase does not explicitly call for violence or harm against any individual or group. \n\n3. Vulgarity and/or Offensive Language: Checking for profanity, slurs, or other offensive language. The phrase does not contain profanity or slurs. However, the phrase 'final solution' is historically associated with the Holocaust and genocide, which could be interpreted as offensive or as a dog whistle in certain contexts. In this post, it is paired with 'Jesus,' which could be interpreted as a religious statement or as a coded reference. However, without further context, it is ambiguous whether the phrase is being used in a hateful or offensive manner, or simply as a religious assertion.",
      "annotation": -1,
      "confidence": 60,
      "guideline_improvement": "when content lacks sufficient information for evaluation (e.g., URLs, non-text media, ambiguous language, or insufficient context) -> refuse to classify (-1)"
    },
    {
      "text_to_annotate": "Drugs in His Pocket, Rope Around His Neck Tied to His Genitals, Sex Toy in His Boots. This, Is CNN. https://imgur.com/JgRJCI5Â  #LiberalFreaks",
      "uid": "06585bdf-b6c4-4a4a-8187-489301ad4bef",
      "edge_case_id": 0.0,
      "pca_x": 0.1314350920297968,
      "pca_y": -0.25437249524252814,
      "raw_annotations": "{\n  \"analysis\": \"1. Assaults on Human Dignity: The post uses the hashtag '#LiberalFreaks', which is a derogatory term aimed at liberals, potentially demeaning a group based on political affiliation. However, political affiliation is not explicitly listed as a protected characteristic in the guideline (which specifies race, ethnicity, gender, religion, sexual orientation, or other protected characteristics). The phrase 'LiberalFreaks' is offensive but not a slur tied to a protected characteristic per the guideline. The rest of the post describes a sensationalized, possibly fabricated scenario, but does not directly demean a protected group. \\n\\n2. Calls for Violence: There is no explicit or implicit incitement or encouragement of physical harm or violence against any individual or group in the post. The text is mocking and sensational, but does not call for violence. \\n\\n3. Vulgarity and/or Offensive Language: The post uses the term 'freaks' in a derogatory way and references sexual content ('rope around his neck tied to his genitals', 'sex toy in his boots'), which is vulgar and intended to be offensive. However, there is no use of profanity or slurs directly targeting a protected group. The language is offensive, but the guideline specifies that offensive language may or may not be directed at individuals or groups. In this case, the offensive language is directed at 'liberals' as a group, but again, political affiliation is not explicitly listed as a protected characteristic in the guideline.\",\n  \"annotation\": \"0\",\n  \"confidence\": 80,\n  \"new_edge_case\": true,\n  \"new_edge_case_rule\": \"When a post contains offensive or vulgar language targeting a political group (not a protected characteristic per the guideline) -> classify as 0 (no hate speech)\"\n}",
      "analyses": "1. Assaults on Human Dignity: The post uses the hashtag '#LiberalFreaks', which is a derogatory term aimed at liberals, potentially demeaning a group based on political affiliation. However, political affiliation is not explicitly listed as a protected characteristic in the guideline (which specifies race, ethnicity, gender, religion, sexual orientation, or other protected characteristics). The phrase 'LiberalFreaks' is offensive but not a slur tied to a protected characteristic per the guideline. The rest of the post describes a sensationalized, possibly fabricated scenario, but does not directly demean a protected group. \n\n2. Calls for Violence: There is no explicit or implicit incitement or encouragement of physical harm or violence against any individual or group in the post. The text is mocking and sensational, but does not call for violence. \n\n3. Vulgarity and/or Offensive Language: The post uses the term 'freaks' in a derogatory way and references sexual content ('rope around his neck tied to his genitals', 'sex toy in his boots'), which is vulgar and intended to be offensive. However, there is no use of profanity or slurs directly targeting a protected group. The language is offensive, but the guideline specifies that offensive language may or may not be directed at individuals or groups. In this case, the offensive language is directed at 'liberals' as a group, but again, political affiliation is not explicitly listed as a protected characteristic in the guideline.",
      "annotation": 0,
      "confidence": 80,
      "guideline_improvement": "when the post targets non-protected groups, individuals, or characteristics (e.g., political groups, institutions, public figures) without explicit calls for violence or slurs targeting protected groups -> classify as 0 (no hate speech)"
    },
    {
      "text_to_annotate": "#CodeRed folks! We are having a literal zombie epidemic. The hate, the vitriol, the mindless slobbering and blabbering. The screaming and the gesturing. Pushing tripping and shoving. Spitting and throwing. These people have LOST their humanity. This is what the #FakeNews media has done to us. #LowIQ #UsefulIdiots on the warpath. We must not engage. We must let this fire burn itself to the ground....",
      "uid": "b635cb33-3ee7-48f2-af05-16139f685aea",
      "edge_case_id": 0.0,
      "pca_x": 0.16454655909415267,
      "pca_y": -0.23983694466797797,
      "raw_annotations": "{\n  \"analysis\": \"Step-by-step evaluation of ALL guideline criteria with text evidence:\\n\\n1. Assaults on Human Dignity:\\n- Guideline: Does the post demean or degrade individuals or groups based on race, ethnicity, gender, religion, sexual orientation, or other protected characteristics?\\n- Evaluation: The post uses dehumanizing language ('literal zombie epidemic', 'mindless slobbering and blabbering', 'These people have LOST their humanity', '#LowIQ', '#UsefulIdiots') to refer to a group of people, apparently those associated with the '#FakeNews media'. However, the group is not explicitly defined by a protected characteristic such as race, ethnicity, gender, religion, or sexual orientation. The group is defined by their perceived association with the media or a political stance, which is not explicitly a protected characteristic per the guideline.\\n\\n2. Calls for Violence:\\n- Guideline: Does the post incite or encourage physical harm or violence against individuals or groups?\\n- Evaluation: The post describes violent actions ('Pushing tripping and shoving. Spitting and throwing.') but does not directly call for or encourage violence. In fact, it says, 'We must not engage. We must let this fire burn itself to the ground,' which suggests not participating in violence.\\n\\n3. Vulgarity and/or Offensive Language:\\n- Guideline: Does the post contain profanity, slurs, or other offensive language that may or may not be directed at individuals or groups?\\n- Evaluation: The post uses derogatory hashtags ('#LowIQ', '#UsefulIdiots') and dehumanizing metaphors ('zombie epidemic', 'mindless slobbering and blabbering', 'LOST their humanity'). While these are offensive and demeaning, they are not traditional slurs or profanity, but they are clearly intended to insult and degrade the targeted group.\\n\\nSummary: The post is highly offensive and dehumanizing toward a group defined by their association with the media or a political stance, but does not target a protected characteristic as specified in the guideline. There is no direct call for violence, and while the language is offensive, it does not use traditional slurs or profanity.\",\n  \"annotation\": \"0\",\n  \"confidence\": 70,\n  \"new_edge_case\": true,\n  \"new_edge_case_rule\": \"When a post uses dehumanizing or highly offensive language toward a group defined by political stance or media association, but not a protected characteristic, and does not call for violence -> classify as 0 (no hate speech)\"\n}",
      "analyses": "Step-by-step evaluation of ALL guideline criteria with text evidence:\n\n1. Assaults on Human Dignity:\n- Guideline: Does the post demean or degrade individuals or groups based on race, ethnicity, gender, religion, sexual orientation, or other protected characteristics?\n- Evaluation: The post uses dehumanizing language ('literal zombie epidemic', 'mindless slobbering and blabbering', 'These people have LOST their humanity', '#LowIQ', '#UsefulIdiots') to refer to a group of people, apparently those associated with the '#FakeNews media'. However, the group is not explicitly defined by a protected characteristic such as race, ethnicity, gender, religion, or sexual orientation. The group is defined by their perceived association with the media or a political stance, which is not explicitly a protected characteristic per the guideline.\n\n2. Calls for Violence:\n- Guideline: Does the post incite or encourage physical harm or violence against individuals or groups?\n- Evaluation: The post describes violent actions ('Pushing tripping and shoving. Spitting and throwing.') but does not directly call for or encourage violence. In fact, it says, 'We must not engage. We must let this fire burn itself to the ground,' which suggests not participating in violence.\n\n3. Vulgarity and/or Offensive Language:\n- Guideline: Does the post contain profanity, slurs, or other offensive language that may or may not be directed at individuals or groups?\n- Evaluation: The post uses derogatory hashtags ('#LowIQ', '#UsefulIdiots') and dehumanizing metaphors ('zombie epidemic', 'mindless slobbering and blabbering', 'LOST their humanity'). While these are offensive and demeaning, they are not traditional slurs or profanity, but they are clearly intended to insult and degrade the targeted group.\n\nSummary: The post is highly offensive and dehumanizing toward a group defined by their association with the media or a political stance, but does not target a protected characteristic as specified in the guideline. There is no direct call for violence, and while the language is offensive, it does not use traditional slurs or profanity.",
      "annotation": 0,
      "confidence": 70,
      "guideline_improvement": "when the post targets non-protected groups, individuals, or characteristics (e.g., political groups, institutions, public figures) without explicit calls for violence or slurs targeting protected groups -> classify as 0 (no hate speech)"
    },
    {
      "text_to_annotate": "I really enjoy the creativity of your posts!  But damn, they are starting to look like a Rothschild costume party.",
      "uid": "4bfad7c1-e399-41dd-989e-7e1e082f8dee",
      "edge_case_id": 5.0,
      "pca_x": -0.014485385681076768,
      "pca_y": 0.12157920020527566,
      "raw_annotations": "{\n  \"analysis\": \"1. Assaults on Human Dignity: The post references 'Rothschild costume party.' The Rothschild family is a common subject of antisemitic conspiracy theories and stereotypes. While the phrase itself does not explicitly demean or degrade based on religion, it can be interpreted as invoking antisemitic tropes, depending on context. However, in this isolated instance, there is no explicit negative statement or clear demeaning language directed at the Rothschilds or Jewish people. The phrase could be interpreted as a veiled reference, but the evidence is ambiguous. \\n\\n2. Calls for Violence: There is no incitement or encouragement of physical harm or violence in the post. No text evidence supports this criterion.\\n\\n3. Vulgarity and/or Offensive Language: The word 'damn' is present, which is mild profanity, but not a slur or highly offensive. There are no slurs or highly offensive terms directed at any group or individual.\\n\\nSummary: The post contains a potentially problematic reference ('Rothschild costume party'), which may allude to antisemitic stereotypes, but does not explicitly demean, degrade, or call for violence. The use of 'damn' is mild and not directed hatefully.\",\n  \"annotation\": \"0\",\n  \"confidence\": 70,\n  \"new_edge_case\": true,\n  \"new_edge_case_rule\": \"When a post contains a potentially coded or ambiguous reference to a protected group (e.g., 'Rothschild') without explicit demeaning language or calls for violence -> classify as 0 unless additional context clarifies intent\"\n}",
      "analyses": "1. Assaults on Human Dignity: The post references 'Rothschild costume party.' The Rothschild family is a common subject of antisemitic conspiracy theories and stereotypes. While the phrase itself does not explicitly demean or degrade based on religion, it can be interpreted as invoking antisemitic tropes, depending on context. However, in this isolated instance, there is no explicit negative statement or clear demeaning language directed at the Rothschilds or Jewish people. The phrase could be interpreted as a veiled reference, but the evidence is ambiguous. \n\n2. Calls for Violence: There is no incitement or encouragement of physical harm or violence in the post. No text evidence supports this criterion.\n\n3. Vulgarity and/or Offensive Language: The word 'damn' is present, which is mild profanity, but not a slur or highly offensive. There are no slurs or highly offensive terms directed at any group or individual.\n\nSummary: The post contains a potentially problematic reference ('Rothschild costume party'), which may allude to antisemitic stereotypes, but does not explicitly demean, degrade, or call for violence. The use of 'damn' is mild and not directed hatefully.",
      "annotation": 0,
      "confidence": 70,
      "guideline_improvement": "when ambiguous/coded references to protected groups lack explicit demeaning language, calls for violence, or clarifying context -> classify as no hate speech (0) but flag for review"
    },
    {
      "text_to_annotate": "I am flexible, I do not require that I sell you the rope I hang you with.",
      "uid": "c73d0a42-a556-4774-a31f-0877b4ddce04",
      "edge_case_id": 2.0,
      "pca_x": 0.14220556051077998,
      "pca_y": -0.002134658740052281,
      "raw_annotations": "{\n  \"analysis\": \"1. Assaults on Human Dignity: Checking if the post demeans or degrades individuals or groups based on protected characteristics (race, ethnicity, gender, religion, sexual orientation, etc.). The post says, 'I am flexible, I do not require that I sell you the rope I hang you with.' There is no explicit or implicit reference to any protected characteristic or group. Not satisfied. 2. Calls for Violence: Checking if the post incites or encourages physical harm or violence against individuals or groups. The phrase 'the rope I hang you with' is a metaphor that references hanging, which is a form of violence. However, the post does not specify a target (individual or group), nor does it incite others to commit violence; it is a statement from the speaker to an unspecified 'you.' There is an implied threat of violence, but no call to action or incitement. Partially satisfied (threatening language, but not incitement). 3. Vulgarity and/or Offensive Language: Checking for profanity, slurs, or other offensive language. The post does not contain profanity or slurs, but the phrase 'the rope I hang you with' could be considered offensive or threatening. Partially satisfied (offensive/threatening metaphor, but not vulgar or slur).\",\n  \"annotation\": \"0\",\n  \"confidence\": 70,\n  \"new_edge_case\": true,\n  \"new_edge_case_rule\": \"When a post contains a metaphorical or implied threat of violence without targeting a protected group or using explicit hate speech language -> classify as 0 (no hate speech) but flag for review\"\n}",
      "analyses": "1. Assaults on Human Dignity: Checking if the post demeans or degrades individuals or groups based on protected characteristics (race, ethnicity, gender, religion, sexual orientation, etc.). The post says, 'I am flexible, I do not require that I sell you the rope I hang you with.' There is no explicit or implicit reference to any protected characteristic or group. Not satisfied. 2. Calls for Violence: Checking if the post incites or encourages physical harm or violence against individuals or groups. The phrase 'the rope I hang you with' is a metaphor that references hanging, which is a form of violence. However, the post does not specify a target (individual or group), nor does it incite others to commit violence; it is a statement from the speaker to an unspecified 'you.' There is an implied threat of violence, but no call to action or incitement. Partially satisfied (threatening language, but not incitement). 3. Vulgarity and/or Offensive Language: Checking for profanity, slurs, or other offensive language. The post does not contain profanity or slurs, but the phrase 'the rope I hang you with' could be considered offensive or threatening. Partially satisfied (offensive/threatening metaphor, but not vulgar or slur).",
      "annotation": 0,
      "confidence": 70,
      "guideline_improvement": "when the post contains references to violence, threats, or aggressive language without inciting harm against protected groups or using explicit hate speech elements -> classify as 0 (no hate speech)"
    },
    {
      "text_to_annotate": "Rest from work? These rats having done any real work since 1945.",
      "uid": "4fd6af0a-7d21-47a6-b86b-694afa3ec862",
      "edge_case_id": 1.0,
      "pca_x": 0.14501516051643187,
      "pca_y": 0.005065719340347941,
      "raw_annotations": "{\n  \"analysis\": \"1. Assaults on Human Dignity: The post uses the term 'rats' to refer to a group of people, which is a dehumanizing slur. However, the group being targeted is not explicitly defined by a protected characteristic (e.g., race, ethnicity, gender, religion, sexual orientation, etc.), but rather by an implied group ('these rats') who allegedly have not worked since 1945. There is no clear evidence in the text that the group is defined by a protected characteristic. \\n\\n2. Calls for Violence: There is no incitement or encouragement of physical harm or violence in the post. No language suggests or encourages violence. \\n\\n3. Vulgarity and/or Offensive Language: The term 'rats' is a derogatory and offensive term when used to refer to people, and the post is clearly intended as an insult. However, it is not a profanity or a widely recognized hate slur, and the target group is not clearly defined by a protected characteristic.\",\n  \"annotation\": \"0\",\n  \"confidence\": 70,\n  \"new_edge_case\": true,\n  \"new_edge_case_rule\": \"When a post uses dehumanizing or offensive language toward an unspecified or ambiguously defined group not clearly linked to a protected characteristic -> classify as 0 (no hate speech) unless additional context clarifies the target group\"\n}",
      "analyses": "1. Assaults on Human Dignity: The post uses the term 'rats' to refer to a group of people, which is a dehumanizing slur. However, the group being targeted is not explicitly defined by a protected characteristic (e.g., race, ethnicity, gender, religion, sexual orientation, etc.), but rather by an implied group ('these rats') who allegedly have not worked since 1945. There is no clear evidence in the text that the group is defined by a protected characteristic. \n\n2. Calls for Violence: There is no incitement or encouragement of physical harm or violence in the post. No language suggests or encourages violence. \n\n3. Vulgarity and/or Offensive Language: The term 'rats' is a derogatory and offensive term when used to refer to people, and the post is clearly intended as an insult. However, it is not a profanity or a widely recognized hate slur, and the target group is not clearly defined by a protected characteristic.",
      "annotation": 0,
      "confidence": 70,
      "guideline_improvement": "when the post references protected groups but lacks explicit assaults on dignity, calls for violence, or vulgarity/offensive language directed at them -> classify as 0 (no hate speech)"
    },
    {
      "text_to_annotate": "I know what could stop all that crying...",
      "uid": "f01b28a8-cc00-484e-a094-53787bc24db9",
      "edge_case_id": 8.0,
      "pca_x": 0.05716809135343487,
      "pca_y": 0.12339265783610956,
      "raw_annotations": "{\n  \"analysis\": \"Step-by-step evaluation of ALL guideline criteria with text evidence:\\n\\n1. Assaults on Human Dignity: The guideline asks if the post demeans or degrades individuals or groups based on protected characteristics (race, ethnicity, gender, religion, sexual orientation, etc.). The text 'I know what could stop all that crying...' does not reference any individual or group, nor does it mention any protected characteristic. Therefore, this criterion is NOT satisfied. Evidence: No mention of any group or characteristic.\\n\\n2. Calls for Violence: The guideline asks if the post incites or encourages physical harm or violence. The text is ambiguous and could be interpreted as a threat in some contexts, but as written, it does not explicitly call for violence or harm. There is no direct or indirect incitement to violence in the text itself. Therefore, this criterion is NOT satisfied. Evidence: No explicit or implicit call for violence.\\n\\n3. Vulgarity and/or Offensive Language: The guideline asks if the post contains profanity, slurs, or other offensive language. The text does not contain any profanity, slurs, or clearly offensive language. Therefore, this criterion is NOT satisfied. Evidence: No vulgar or offensive words present.\\n\\nOverall, the post is ambiguous and could be interpreted as menacing or threatening depending on context, but with the information given and the guideline's requirements, none of the hate speech criteria are satisfied.\",\n  \"annotation\": \"0\",\n  \"confidence\": 70,\n  \"new_edge_case\": true,\n  \"new_edge_case_rule\": \"When a post contains ambiguous or potentially menacing language without explicit reference to protected characteristics, violence, or offensive language -> classify as 0 (no hate speech) unless additional context is provided\"\n}",
      "analyses": "Step-by-step evaluation of ALL guideline criteria with text evidence:\n\n1. Assaults on Human Dignity: The guideline asks if the post demeans or degrades individuals or groups based on protected characteristics (race, ethnicity, gender, religion, sexual orientation, etc.). The text 'I know what could stop all that crying...' does not reference any individual or group, nor does it mention any protected characteristic. Therefore, this criterion is NOT satisfied. Evidence: No mention of any group or characteristic.\n\n2. Calls for Violence: The guideline asks if the post incites or encourages physical harm or violence. The text is ambiguous and could be interpreted as a threat in some contexts, but as written, it does not explicitly call for violence or harm. There is no direct or indirect incitement to violence in the text itself. Therefore, this criterion is NOT satisfied. Evidence: No explicit or implicit call for violence.\n\n3. Vulgarity and/or Offensive Language: The guideline asks if the post contains profanity, slurs, or other offensive language. The text does not contain any profanity, slurs, or clearly offensive language. Therefore, this criterion is NOT satisfied. Evidence: No vulgar or offensive words present.\n\nOverall, the post is ambiguous and could be interpreted as menacing or threatening depending on context, but with the information given and the guideline's requirements, none of the hate speech criteria are satisfied.",
      "annotation": 0,
      "confidence": 70,
      "guideline_improvement": "when content lacks explicit evidence of demeaning language, calls for violence, or offensive slurs targeting protected characteristics, despite potential ambiguity, sarcasm, indirect references, or coded language -> classify as 0 (no hate speech) with low confidence due to ambiguity"
    },
    {
      "text_to_annotate": "Yey for gay! Fuckin Obama social experiments.Â  https://www.nbcnews.com/feature/nbc-out/navy-drag-...",
      "uid": "bb01ff8b-1d55-4f3c-9a00-7e2800461b8c",
      "edge_case_id": 8.0,
      "pca_x": 0.059062099358339615,
      "pca_y": 0.1994063599588539,
      "raw_annotations": "{\n  \"analysis\": \"1. Assaults on Human Dignity: This criterion checks for demeaning or degrading language targeting protected characteristics such as sexual orientation or political affiliation. The phrase 'Yey for gay!' could be interpreted as supportive or sarcastic, but without further context, the intent is ambiguous. The phrase 'Fuckin Obama social experiments' uses profanity and references 'Obama social experiments,' which could be interpreted as a derogatory reference to policies associated with LGBTQ+ rights, but it is not explicitly demeaning or degrading to a protected group in a clear, direct way. 2. Calls for Violence: There is no incitement or encouragement of physical harm or violence against any individual or group in the post. 3. Vulgarity and/or Offensive Language: The post contains profanity ('Fuckin'), which is offensive language, but it is not clearly directed as a slur or hate term at a specific group or individual. The use of 'Fuckin' modifies 'Obama social experiments,' which is a political reference, not a protected characteristic. There are no explicit slurs or hate terms present.\",\n  \"annotation\": \"0\",\n  \"confidence\": 70,\n  \"new_edge_case\": true,\n  \"new_edge_case_rule\": \"When a post contains ambiguous or sarcastic language referencing protected characteristics, but lacks clear evidence of demeaning intent or explicit slurs, and only contains general profanity -> classify as 0 (no hate speech) with low confidence\"\n}",
      "analyses": "1. Assaults on Human Dignity: This criterion checks for demeaning or degrading language targeting protected characteristics such as sexual orientation or political affiliation. The phrase 'Yey for gay!' could be interpreted as supportive or sarcastic, but without further context, the intent is ambiguous. The phrase 'Fuckin Obama social experiments' uses profanity and references 'Obama social experiments,' which could be interpreted as a derogatory reference to policies associated with LGBTQ+ rights, but it is not explicitly demeaning or degrading to a protected group in a clear, direct way. 2. Calls for Violence: There is no incitement or encouragement of physical harm or violence against any individual or group in the post. 3. Vulgarity and/or Offensive Language: The post contains profanity ('Fuckin'), which is offensive language, but it is not clearly directed as a slur or hate term at a specific group or individual. The use of 'Fuckin' modifies 'Obama social experiments,' which is a political reference, not a protected characteristic. There are no explicit slurs or hate terms present.",
      "annotation": 0,
      "confidence": 70,
      "guideline_improvement": "when content lacks explicit evidence of demeaning language, calls for violence, or offensive slurs targeting protected characteristics, despite potential ambiguity, sarcasm, indirect references, or coded language -> classify as 0 (no hate speech) with low confidence due to ambiguity"
    },
    {
      "text_to_annotate": "Liberal collateral damage.",
      "uid": "2baf3c1e-057d-4a7a-b502-49c0a10cfbaa",
      "edge_case_id": 8.0,
      "pca_x": 0.0625002067542813,
      "pca_y": 0.18774121899103322,
      "raw_annotations": "{\n  \"analysis\": \"1. Assaults on Human Dignity: Checking if the post demeans or degrades individuals or groups based on protected characteristics. The phrase 'Liberal collateral damage' references 'liberals' (a political ideology/group), but does not explicitly demean, degrade, or insult them. No direct evidence of demeaning language is present. Not satisfied. 2. Calls for Violence: Checking if the post incites or encourages physical harm or violence. The phrase 'collateral damage' can imply harm, but in this context, it is ambiguous whether it is a literal call for violence or a figurative/political statement. There is no explicit incitement or encouragement of violence. Not satisfied. 3. Vulgarity and/or Offensive Language: Checking for profanity, slurs, or offensive language. The phrase does not contain profanity or slurs. Not satisfied.\",\n  \"annotation\": \"0\",\n  \"confidence\": 70,\n  \"new_edge_case\": true,\n  \"new_edge_case_rule\": \"When a post uses ambiguous or figurative language that could imply harm to a political group but lacks explicit demeaning, violent, or profane content -> classify as 0 (no hate speech) with low confidence\"\n}",
      "analyses": "1. Assaults on Human Dignity: Checking if the post demeans or degrades individuals or groups based on protected characteristics. The phrase 'Liberal collateral damage' references 'liberals' (a political ideology/group), but does not explicitly demean, degrade, or insult them. No direct evidence of demeaning language is present. Not satisfied. 2. Calls for Violence: Checking if the post incites or encourages physical harm or violence. The phrase 'collateral damage' can imply harm, but in this context, it is ambiguous whether it is a literal call for violence or a figurative/political statement. There is no explicit incitement or encouragement of violence. Not satisfied. 3. Vulgarity and/or Offensive Language: Checking for profanity, slurs, or offensive language. The phrase does not contain profanity or slurs. Not satisfied.",
      "annotation": 0,
      "confidence": 70,
      "guideline_improvement": "when content lacks explicit evidence of demeaning language, calls for violence, or offensive slurs targeting protected characteristics, despite potential ambiguity, sarcasm, indirect references, or coded language -> classify as 0 (no hate speech) with low confidence due to ambiguity"
    },
    {
      "text_to_annotate": "'I find wearing these little yellow stars on the chest is a good way to expiate our past sins, it reminds us of our privilege and keeps the memory of our crimes alive now that the last nazi is dead.' Conservative, circa 2025. #ConservativeMindset",
      "uid": "0dc256e0-c787-4732-a49e-9b383e26faf7",
      "edge_case_id": 6.0,
      "pca_x": 0.037044927027997165,
      "pca_y": -0.16047386327958615,
      "raw_annotations": "{\n  \"analysis\": \"1. Assaults on Human Dignity: The post references 'wearing these little yellow stars on the chest,' which is a clear allusion to the yellow Star of David that Jews were forced to wear during the Holocaust. The phrase 'expiate our past sins' and 'keeps the memory of our crimes alive now that the last nazi is dead' appears to be a sarcastic or provocative statement about collective guilt and privilege. However, the post does not directly demean or degrade a specific group based on protected characteristics; rather, it uses historical references in a potentially insensitive or provocative way. There is no explicit demeaning language directed at a group, but the use of Holocaust imagery in a political context can be considered offensive and trivializing to the suffering of Holocaust victims. \\n2. Calls for Violence: There is no incitement or encouragement of physical harm or violence against any individual or group in the post. No text evidence supports this criterion. \\n3. Vulgarity and/or Offensive Language: The post does not contain profanity or explicit slurs. However, the use of Holocaust symbolism in a political context can be considered highly offensive, especially to Jewish people and Holocaust survivors, as it trivializes historical atrocities. The offensiveness is contextual and not based on explicit language, but on the inappropriate use of historical symbols.\",\n  \"annotation\": \"1\",\n  \"confidence\": 80,\n  \"new_edge_case\": true,\n  \"new_edge_case_rule\": \"When a post uses historically charged symbols (e.g., Holocaust imagery) in a political or sarcastic context that trivializes atrocities, even without explicit slurs or calls for violence, and the offensiveness arises from the context and symbolism rather than direct language -> classify as hate speech (1)\"\n}",
      "analyses": "1. Assaults on Human Dignity: The post references 'wearing these little yellow stars on the chest,' which is a clear allusion to the yellow Star of David that Jews were forced to wear during the Holocaust. The phrase 'expiate our past sins' and 'keeps the memory of our crimes alive now that the last nazi is dead' appears to be a sarcastic or provocative statement about collective guilt and privilege. However, the post does not directly demean or degrade a specific group based on protected characteristics; rather, it uses historical references in a potentially insensitive or provocative way. There is no explicit demeaning language directed at a group, but the use of Holocaust imagery in a political context can be considered offensive and trivializing to the suffering of Holocaust victims. \n2. Calls for Violence: There is no incitement or encouragement of physical harm or violence against any individual or group in the post. No text evidence supports this criterion. \n3. Vulgarity and/or Offensive Language: The post does not contain profanity or explicit slurs. However, the use of Holocaust symbolism in a political context can be considered highly offensive, especially to Jewish people and Holocaust survivors, as it trivializes historical atrocities. The offensiveness is contextual and not based on explicit language, but on the inappropriate use of historical symbols.",
      "annotation": 1,
      "confidence": 80,
      "guideline_improvement": "when a post dehumanizes protected groups by invalidating identities or trivializing atrocities through symbolism/narratives -> classify as hate speech (1)"
    },
    {
      "text_to_annotate": "https://www.youtube.com/watch?v=7sgHIrts8EQ  ",
      "uid": "c24e2723-9c32-4b0d-b2d8-f49e937cb099",
      "edge_case_id": 4.0,
      "pca_x": -0.6497294570253775,
      "pca_y": -0.20131154602454907,
      "raw_annotations": "{\n  \"analysis\": \"1. Assaults on Human Dignity: The post consists solely of a URL ('https://www.youtube.com/watch?v=7sgHIrts8EQ'). There is no text content that can be evaluated for demeaning or degrading language toward individuals or groups. Guideline not satisfied. Evidence: No evaluable text. \\n2. Calls for Violence: There is no text content in the post that could incite or encourage violence. Guideline not satisfied. Evidence: No evaluable text. \\n3. Vulgarity and/or Offensive Language: The post contains only a URL and no language that could be considered profane, slurring, or offensive. Guideline not satisfied. Evidence: No evaluable text.\",\n  \"annotation\": \"-1\",\n  \"confidence\": 60,\n  \"new_edge_case\": true,\n  \"new_edge_case_rule\": \"When a post contains only a URL or non-linguistic content with no evaluable text -> refuse to classify (-1)\"\n}",
      "analyses": "1. Assaults on Human Dignity: The post consists solely of a URL ('https://www.youtube.com/watch?v=7sgHIrts8EQ'). There is no text content that can be evaluated for demeaning or degrading language toward individuals or groups. Guideline not satisfied. Evidence: No evaluable text. \n2. Calls for Violence: There is no text content in the post that could incite or encourage violence. Guideline not satisfied. Evidence: No evaluable text. \n3. Vulgarity and/or Offensive Language: The post contains only a URL and no language that could be considered profane, slurring, or offensive. Guideline not satisfied. Evidence: No evaluable text.",
      "annotation": -1,
      "confidence": 60,
      "guideline_improvement": "when content lacks sufficient information for evaluation (e.g., URLs, non-text media, ambiguous language, or insufficient context) -> refuse to classify (-1)"
    },
    {
      "text_to_annotate": "I actually doubt this, and here's why: TDS needs Eric Striker for shekels. The only show worth listening to behind the paywall is Strike and Mike, and everyone knows it.Â   Jazz and Jesse fucking blows, and an extra episode of TDS isn't worth it for a lot of people. I'm sure they would love to get rid of him though, but they can't.",
      "uid": "3c1c801e-0455-4350-ba2b-a4017c7937ed",
      "edge_case_id": 5.0,
      "pca_x": 0.0849061083844585,
      "pca_y": 0.23523275652732098,
      "raw_annotations": "{\n  \"analysis\": \"1. Assaults on Human Dignity: Checking for demeaning or degrading language based on protected characteristics (race, ethnicity, gender, religion, sexual orientation, etc.). The post references 'TDS', 'Eric Striker', 'Strike and Mike', 'Jazz and Jesse', but does not explicitly demean or degrade any individual or group based on protected characteristics. The phrase 'needs Eric Striker for shekels' could be interpreted as an antisemitic trope if contextually 'shekels' is used as a slur referencing Jewish people and money, but in this post, it is not explicitly clear that it is being used in that way. No other evidence of assaults on human dignity is present. \\n2. Calls for Violence: There is no incitement or encouragement of physical harm or violence against any individual or group in the post. \\n3. Vulgarity and/or Offensive Language: The post contains profanity ('fucking blows'), which is offensive language, but it is directed at the quality of a show ('Jazz and Jesse fucking blows'), not at a person or group based on protected characteristics. No slurs are present. \\n\\nSummary: The post contains offensive language but does not clearly target protected characteristics or incite violence. The use of 'shekels' could be an antisemitic dogwhistle, but without more context, it is ambiguous whether it is being used as a slur or simply as slang for money.\",\n  \"annotation\": \"0\",\n  \"confidence\": 65,\n  \"new_edge_case\": true,\n  \"new_edge_case_rule\": \"When a term with potential as a hate speech dogwhistle (e.g., 'shekels') is used ambiguously without clear context indicating targeting of a protected group -> classify as 0 (no hate speech) but flag for review\"\n}",
      "analyses": "1. Assaults on Human Dignity: Checking for demeaning or degrading language based on protected characteristics (race, ethnicity, gender, religion, sexual orientation, etc.). The post references 'TDS', 'Eric Striker', 'Strike and Mike', 'Jazz and Jesse', but does not explicitly demean or degrade any individual or group based on protected characteristics. The phrase 'needs Eric Striker for shekels' could be interpreted as an antisemitic trope if contextually 'shekels' is used as a slur referencing Jewish people and money, but in this post, it is not explicitly clear that it is being used in that way. No other evidence of assaults on human dignity is present. \n2. Calls for Violence: There is no incitement or encouragement of physical harm or violence against any individual or group in the post. \n3. Vulgarity and/or Offensive Language: The post contains profanity ('fucking blows'), which is offensive language, but it is directed at the quality of a show ('Jazz and Jesse fucking blows'), not at a person or group based on protected characteristics. No slurs are present. \n\nSummary: The post contains offensive language but does not clearly target protected characteristics or incite violence. The use of 'shekels' could be an antisemitic dogwhistle, but without more context, it is ambiguous whether it is being used as a slur or simply as slang for money.",
      "annotation": 0,
      "confidence": 65,
      "guideline_improvement": "when ambiguous/coded references to protected groups lack explicit demeaning language, calls for violence, or clarifying context -> classify as no hate speech (0) but flag for review"
    },
    {
      "text_to_annotate": "Technically possible that South Africa is a systemic risk for West and the East.Â  1. Export health risk (40% of deaths attributed to AIDS) 2. Security risk (Desire to attack whites and American soldiers in Venezuela specifically) 3. Highly transacted currency and logistic impediment. @alternative_rightÂ @ANVÂ @seamrogÂ @arquatrixÂ @KMGVictoria",
      "uid": "f001e57d-2a18-4096-8a59-595b33f701ae",
      "edge_case_id": 8.0,
      "pca_x": 0.11440936517397043,
      "pca_y": 0.2133569148824199,
      "raw_annotations": "{\n  \"analysis\": \"1. Assaults on Human Dignity: This criterion checks for demeaning or degrading statements about individuals or groups based on protected characteristics. The post states, 'Desire to attack whites and American soldiers in Venezuela specifically.' This references a desire to attack specific groups (whites, American soldiers), but it is not clear if the post itself is expressing this desire or reporting it as a risk. The phrase is ambiguous and could be interpreted as either reporting a perceived threat or endorsing it. There is no explicit demeaning or degrading language directed at these groups, but the mention of 'Desire to attack whites and American soldiers' could be construed as referencing hate or violence against protected groups. \\n2. Calls for Violence: This criterion checks for incitement or encouragement of violence. The post does not directly call for or encourage violence. It mentions a 'Desire to attack whites and American soldiers,' but it is not clear if the author is endorsing or simply reporting this as a risk. There is no explicit call to action or encouragement of violence in the text. \\n3. Vulgarity and/or Offensive Language: This criterion checks for profanity, slurs, or other offensive language. The post does not contain any profanity, slurs, or overtly offensive language. The language is formal and analytical in tone, though the content is sensitive.\",\n  \"annotation\": \"0\",\n  \"confidence\": 70,\n  \"new_edge_case\": true,\n  \"new_edge_case_rule\": \"When a post references a desire or threat of violence against protected groups but does not clearly endorse or incite it, and the language is ambiguous as to intent -> classify as 0 (no hate speech) with low confidence\"\n}",
      "analyses": "1. Assaults on Human Dignity: This criterion checks for demeaning or degrading statements about individuals or groups based on protected characteristics. The post states, 'Desire to attack whites and American soldiers in Venezuela specifically.' This references a desire to attack specific groups (whites, American soldiers), but it is not clear if the post itself is expressing this desire or reporting it as a risk. The phrase is ambiguous and could be interpreted as either reporting a perceived threat or endorsing it. There is no explicit demeaning or degrading language directed at these groups, but the mention of 'Desire to attack whites and American soldiers' could be construed as referencing hate or violence against protected groups. \n2. Calls for Violence: This criterion checks for incitement or encouragement of violence. The post does not directly call for or encourage violence. It mentions a 'Desire to attack whites and American soldiers,' but it is not clear if the author is endorsing or simply reporting this as a risk. There is no explicit call to action or encouragement of violence in the text. \n3. Vulgarity and/or Offensive Language: This criterion checks for profanity, slurs, or other offensive language. The post does not contain any profanity, slurs, or overtly offensive language. The language is formal and analytical in tone, though the content is sensitive.",
      "annotation": 0,
      "confidence": 70,
      "guideline_improvement": "when content lacks explicit evidence of demeaning language, calls for violence, or offensive slurs targeting protected characteristics, despite potential ambiguity, sarcasm, indirect references, or coded language -> classify as 0 (no hate speech) with low confidence due to ambiguity"
    },
    {
      "text_to_annotate": "These two will fix the GOP in Kalifornistan? http://angry.net/blog2/?p=25838",
      "uid": "8f2c8f01-1307-4af8-ba39-01b3d08f6c0b",
      "edge_case_id": 5.0,
      "pca_x": 0.15079564373467852,
      "pca_y": 0.06358186747760211,
      "raw_annotations": "{\n  \"analysis\": \"1. Assaults on Human Dignity: The post uses the term 'Kalifornistan' to refer to California. This is a portmanteau of 'California' and 'Stan' (as in Afghanistan, Pakistan, etc.), which is sometimes used pejoratively to suggest that California is like a foreign, often Muslim-majority, country. The intent is often to demean or mock the state and its perceived political or cultural characteristics, sometimes with xenophobic or Islamophobic undertones. However, the post does not explicitly target a protected group (e.g., race, religion) but rather a geographic region (California) and a political party (GOP). There is an implied negative comparison, but it is not directly demeaning a protected group. Not satisfied, but borderline.\\n\\n2. Calls for Violence: There is no language in the post that incites or encourages physical harm or violence against any individual or group. Not satisfied. Evidence: No calls for violence present.\\n\\n3. Vulgarity and/or Offensive Language: The term 'Kalifornistan' is a derogatory neologism, potentially offensive, especially to Californians or those of Central/South Asian descent, but it is not a direct slur or profanity. The rest of the language is not vulgar or profane. Not satisfied for explicit vulgarity or slurs, but the term is arguably offensive depending on interpretation.\",\n  \"annotation\": \"0\",\n  \"confidence\": 70,\n  \"new_edge_case\": true,\n  \"new_edge_case_rule\": \"When a neologism or portmanteau is used to mock a region or political entity with possible but indirect reference to a protected group, and there is no explicit demeaning, violence, or slur, but potential for offense exists -> classify as 0 (no hate speech) unless direct targeting of a protected group is evident\"\n}",
      "analyses": "1. Assaults on Human Dignity: The post uses the term 'Kalifornistan' to refer to California. This is a portmanteau of 'California' and 'Stan' (as in Afghanistan, Pakistan, etc.), which is sometimes used pejoratively to suggest that California is like a foreign, often Muslim-majority, country. The intent is often to demean or mock the state and its perceived political or cultural characteristics, sometimes with xenophobic or Islamophobic undertones. However, the post does not explicitly target a protected group (e.g., race, religion) but rather a geographic region (California) and a political party (GOP). There is an implied negative comparison, but it is not directly demeaning a protected group. Not satisfied, but borderline.\n\n2. Calls for Violence: There is no language in the post that incites or encourages physical harm or violence against any individual or group. Not satisfied. Evidence: No calls for violence present.\n\n3. Vulgarity and/or Offensive Language: The term 'Kalifornistan' is a derogatory neologism, potentially offensive, especially to Californians or those of Central/South Asian descent, but it is not a direct slur or profanity. The rest of the language is not vulgar or profane. Not satisfied for explicit vulgarity or slurs, but the term is arguably offensive depending on interpretation.",
      "annotation": 0,
      "confidence": 70,
      "guideline_improvement": "when ambiguous/coded references to protected groups lack explicit demeaning language, calls for violence, or clarifying context -> classify as no hate speech (0) but flag for review"
    },
    {
      "text_to_annotate": "#Muzhood Agent Obama with Appointed Muzhood Agents, ",
      "uid": "d99b697f-14f3-4c8a-bd85-40310cda4260",
      "edge_case_id": 4.0,
      "pca_x": -0.3039667260152772,
      "pca_y": 0.2889350671987556,
      "raw_annotations": "{\n  \"analysis\": \"1. Assaults on Human Dignity: This criterion checks for demeaning or degrading language based on protected characteristics (race, ethnicity, religion, etc.). The post uses the term 'Muzhood' in reference to 'Agent Obama' and 'Appointed Muzhood Agents.' The term 'Muzhood' appears to be a play on 'Muslim' or a derogatory alteration, but without further context or established slur status, it is unclear if it is inherently demeaning or degrading. No explicit evidence of demeaning language is present in the text itself. \\n\\n2. Calls for Violence: This criterion checks for incitement or encouragement of physical harm or violence. The post does not contain any language that incites or encourages violence against any individual or group. \\n\\n3. Vulgarity and/or Offensive Language: This criterion checks for profanity, slurs, or other offensive language. The term 'Muzhood' could potentially be a slur or offensive, but it is not a widely recognized slur, and the post does not contain any other profanity or clearly offensive language. The intent and offensiveness of 'Muzhood' are ambiguous without additional context.\",\n  \"annotation\": \"-1\",\n  \"confidence\": 50,\n  \"new_edge_case\": true,\n  \"new_edge_case_rule\": \"When a potentially offensive or coded term is used but its meaning and offensiveness are ambiguous or unestablished in common usage -> refuse to classify (-1)\"\n}",
      "analyses": "1. Assaults on Human Dignity: This criterion checks for demeaning or degrading language based on protected characteristics (race, ethnicity, religion, etc.). The post uses the term 'Muzhood' in reference to 'Agent Obama' and 'Appointed Muzhood Agents.' The term 'Muzhood' appears to be a play on 'Muslim' or a derogatory alteration, but without further context or established slur status, it is unclear if it is inherently demeaning or degrading. No explicit evidence of demeaning language is present in the text itself. \n\n2. Calls for Violence: This criterion checks for incitement or encouragement of physical harm or violence. The post does not contain any language that incites or encourages violence against any individual or group. \n\n3. Vulgarity and/or Offensive Language: This criterion checks for profanity, slurs, or other offensive language. The term 'Muzhood' could potentially be a slur or offensive, but it is not a widely recognized slur, and the post does not contain any other profanity or clearly offensive language. The intent and offensiveness of 'Muzhood' are ambiguous without additional context.",
      "annotation": -1,
      "confidence": 50,
      "guideline_improvement": "when content lacks sufficient information for evaluation (e.g., URLs, non-text media, ambiguous language, or insufficient context) -> refuse to classify (-1)"
    },
    {
      "text_to_annotate": "one thing that some don't know is in spain they think people from mexico and south america and cuba are lower forms of life ,reason there not spainish andÂ Â  not white this is true i have heard this before,you find racism every part of the world .",
      "uid": "ebf49d56-de10-4edd-8d02-83e37ace3516",
      "edge_case_id": 7.0,
      "pca_x": 0.10899245727176837,
      "pca_y": 0.017954103693945858,
      "raw_annotations": "{\n  \"analysis\": \"1. Assaults on Human Dignity: This criterion checks if the post demeans or degrades individuals or groups based on protected characteristics. The post states, 'in spain they think people from mexico and south america and cuba are lower forms of life, reason there not spainish and not white.' This is a report of a prejudiced attitude attributed to people in Spain, not a direct statement from the poster. The phrase 'lower forms of life' is highly demeaning, but it is presented as an alleged belief of others, not the poster's own view. 2. Calls for Violence: The post does not incite or encourage physical harm or violence against any group or individual. No language in the post calls for or supports violence. 3. Vulgarity and/or Offensive Language: The phrase 'lower forms of life' is extremely offensive and dehumanizing, but it is used in the context of reporting what the poster claims is the attitude of some people in Spain, not as a direct insult from the poster. There is no profanity or slur used by the poster themselves.\",\n  \"annotation\": \"0\",\n  \"confidence\": 70,\n  \"new_edge_case\": true,\n  \"new_edge_case_rule\": \"When a post reports or describes hate speech or prejudice as the alleged views of others, without endorsing or expressing those views directly, and without using slurs or inciting violence, but uses highly offensive language in the description -> classify as 0 (no hate speech), but flag for review if context is ambiguous.\"\n}",
      "analyses": "1. Assaults on Human Dignity: This criterion checks if the post demeans or degrades individuals or groups based on protected characteristics. The post states, 'in spain they think people from mexico and south america and cuba are lower forms of life, reason there not spainish and not white.' This is a report of a prejudiced attitude attributed to people in Spain, not a direct statement from the poster. The phrase 'lower forms of life' is highly demeaning, but it is presented as an alleged belief of others, not the poster's own view. 2. Calls for Violence: The post does not incite or encourage physical harm or violence against any group or individual. No language in the post calls for or supports violence. 3. Vulgarity and/or Offensive Language: The phrase 'lower forms of life' is extremely offensive and dehumanizing, but it is used in the context of reporting what the poster claims is the attitude of some people in Spain, not as a direct insult from the poster. There is no profanity or slur used by the poster themselves.",
      "annotation": 0,
      "confidence": 70,
      "guideline_improvement": "when content reports offensive material or uses insensitive language without direct targeting of protected groups -> classify as no hate speech (0) but flag for review/insensitivity"
    },
    {
      "text_to_annotate": "#NotSendingTheirBest",
      "uid": "0bbae341-7b77-4f72-baba-9a4ce6bc46a9",
      "edge_case_id": 5.0,
      "pca_x": 0.14343082294423604,
      "pca_y": 0.05423000533574765,
      "raw_annotations": "{\n  \"analysis\": \"Step-by-step evaluation of ALL guideline criteria with text evidence:\\n\\n1. Assaults on Human Dignity: The guideline asks if the post demeans or degrades individuals or groups based on protected characteristics. The hashtag '#NotSendingTheirBest' is a phrase that has been used in some contexts to refer to immigrants or groups, often in a derogatory way. However, in this isolated form, the post does not explicitly mention any group, individual, or protected characteristic. There is no direct evidence in the text itself that it is demeaning or degrading anyone. Therefore, this criterion is NOT satisfied.\\n\\n2. Calls for Violence: The post does not incite or encourage physical harm or violence against any individual or group. There is no language suggesting violence. This criterion is NOT satisfied.\\n\\n3. Vulgarity and/or Offensive Language: The post does not contain profanity, slurs, or other offensive language. The phrase itself is not inherently vulgar or a slur. This criterion is NOT satisfied.\\n\\nText evidence: The only content is the hashtag '#NotSendingTheirBest', with no explicit reference to any group, individual, or protected characteristic, and no offensive or violent language.\",\n  \"annotation\": \"0\",\n  \"confidence\": 80,\n  \"new_edge_case\": true,\n  \"new_edge_case_rule\": \"When a phrase with known hateful connotations is used in isolation without explicit reference to a group or protected characteristic -> classify as no hate speech (0) unless context is provided\"\n}",
      "analyses": "Step-by-step evaluation of ALL guideline criteria with text evidence:\n\n1. Assaults on Human Dignity: The guideline asks if the post demeans or degrades individuals or groups based on protected characteristics. The hashtag '#NotSendingTheirBest' is a phrase that has been used in some contexts to refer to immigrants or groups, often in a derogatory way. However, in this isolated form, the post does not explicitly mention any group, individual, or protected characteristic. There is no direct evidence in the text itself that it is demeaning or degrading anyone. Therefore, this criterion is NOT satisfied.\n\n2. Calls for Violence: The post does not incite or encourage physical harm or violence against any individual or group. There is no language suggesting violence. This criterion is NOT satisfied.\n\n3. Vulgarity and/or Offensive Language: The post does not contain profanity, slurs, or other offensive language. The phrase itself is not inherently vulgar or a slur. This criterion is NOT satisfied.\n\nText evidence: The only content is the hashtag '#NotSendingTheirBest', with no explicit reference to any group, individual, or protected characteristic, and no offensive or violent language.",
      "annotation": 0,
      "confidence": 80,
      "guideline_improvement": "when ambiguous/coded references to protected groups lack explicit demeaning language, calls for violence, or clarifying context -> classify as no hate speech (0) but flag for review"
    },
    {
      "text_to_annotate": "America will be great again especially after all of these people who made it a nightmare die off!! Good riddance!",
      "uid": "8779a39e-ae6c-46af-8d36-bdf4c9f606f8",
      "edge_case_id": 7.0,
      "pca_x": 0.1390385777897375,
      "pca_y": -0.15927062493020164,
      "raw_annotations": "{\n  \"analysis\": \"1. Assaults on Human Dignity: Checking if the post demeans or degrades individuals or groups based on protected characteristics. The phrase 'all of these people who made it a nightmare' is vague and does not specify any protected characteristic (race, ethnicity, gender, religion, etc.), so this criterion is NOT satisfied. Evidence: No explicit mention of a protected group.\\n2. Calls for Violence: Checking if the post incites or encourages physical harm or violence. The post says 'after all of these people who made it a nightmare die off!! Good riddance!' which expresses a wish for death upon a group of people, though it does not directly incite violence or call for action, it does celebrate or wish for their death. This is borderline, but since it does not explicitly call for violence, this criterion is NOT strictly satisfied. Evidence: 'die off' is a wish, not a call to action.\\n3. Vulgarity and/or Offensive Language: Checking for profanity, slurs, or offensive language. The phrase 'Good riddance!' is dismissive and hostile, but not profane or a slur. No explicit vulgarity or offensive language is present. This criterion is NOT satisfied. Evidence: No profanity or slurs.\",\n  \"annotation\": \"0\",\n  \"confidence\": 65,\n  \"new_edge_case\": true,\n  \"new_edge_case_rule\": \"When a post expresses a wish for death or harm to an unspecified group without reference to protected characteristics and without explicit incitement to violence -> classify as 0 (no hate speech)\"\n}",
      "analyses": "1. Assaults on Human Dignity: Checking if the post demeans or degrades individuals or groups based on protected characteristics. The phrase 'all of these people who made it a nightmare' is vague and does not specify any protected characteristic (race, ethnicity, gender, religion, etc.), so this criterion is NOT satisfied. Evidence: No explicit mention of a protected group.\n2. Calls for Violence: Checking if the post incites or encourages physical harm or violence. The post says 'after all of these people who made it a nightmare die off!! Good riddance!' which expresses a wish for death upon a group of people, though it does not directly incite violence or call for action, it does celebrate or wish for their death. This is borderline, but since it does not explicitly call for violence, this criterion is NOT strictly satisfied. Evidence: 'die off' is a wish, not a call to action.\n3. Vulgarity and/or Offensive Language: Checking for profanity, slurs, or offensive language. The phrase 'Good riddance!' is dismissive and hostile, but not profane or a slur. No explicit vulgarity or offensive language is present. This criterion is NOT satisfied. Evidence: No profanity or slurs.",
      "annotation": 0,
      "confidence": 65,
      "guideline_improvement": "when content reports offensive material or uses insensitive language without direct targeting of protected groups -> classify as no hate speech (0) but flag for review/insensitivity"
    },
    {
      "text_to_annotate": "Mainstream Muslims on murder of gays! https://youtu.be/AkXfs8VDu2Q",
      "uid": "31236f9c-8a09-49e7-b74f-b9bfb7914e37",
      "edge_case_id": 8.0,
      "pca_x": 0.020916122760229527,
      "pca_y": 0.20027056916983113,
      "raw_annotations": "{\n  \"analysis\": \"1. Assaults on Human Dignity: Checking if the post demeans or degrades individuals or groups based on protected characteristics. The phrase 'Mainstream Muslims on murder of gays!' references both a religious group (Muslims) and a sexual orientation group (gays). The wording is ambiguous: it could be interpreted as suggesting that mainstream Muslims support or condone the murder of gay people, which would be a demeaning generalization about Muslims and could also be seen as demeaning to gay people by trivializing violence against them. However, the post itself does not explicitly state an opinion or make a direct derogatory statement; it references a video, and the actual content or stance is not clear from the text alone. \\n2. Calls for Violence: Checking for incitement or encouragement of violence. The post mentions 'murder of gays' but does not directly call for or encourage violence; it references a topic or discussion, not an explicit call to action. \\n3. Vulgarity and/or Offensive Language: Checking for profanity, slurs, or offensive language. The post does not contain profanity or slurs, but the phrase 'murder of gays' is highly sensitive and potentially offensive, depending on context. However, it is not used as a slur or in a profane manner in the text itself.\",\n  \"annotation\": \"0\",\n  \"confidence\": 60,\n  \"new_edge_case\": true,\n  \"new_edge_case_rule\": \"When a post references a controversial or potentially hateful topic via a link or ambiguous phrasing, without explicit endorsement, demeaning language, or calls for violence in the text itself -> classify as 0 (no hate speech) but flag for low confidence due to ambiguity\"\n}",
      "analyses": "1. Assaults on Human Dignity: Checking if the post demeans or degrades individuals or groups based on protected characteristics. The phrase 'Mainstream Muslims on murder of gays!' references both a religious group (Muslims) and a sexual orientation group (gays). The wording is ambiguous: it could be interpreted as suggesting that mainstream Muslims support or condone the murder of gay people, which would be a demeaning generalization about Muslims and could also be seen as demeaning to gay people by trivializing violence against them. However, the post itself does not explicitly state an opinion or make a direct derogatory statement; it references a video, and the actual content or stance is not clear from the text alone. \n2. Calls for Violence: Checking for incitement or encouragement of violence. The post mentions 'murder of gays' but does not directly call for or encourage violence; it references a topic or discussion, not an explicit call to action. \n3. Vulgarity and/or Offensive Language: Checking for profanity, slurs, or offensive language. The post does not contain profanity or slurs, but the phrase 'murder of gays' is highly sensitive and potentially offensive, depending on context. However, it is not used as a slur or in a profane manner in the text itself.",
      "annotation": 0,
      "confidence": 60,
      "guideline_improvement": "when content lacks explicit evidence of demeaning language, calls for violence, or offensive slurs targeting protected characteristics, despite potential ambiguity, sarcasm, indirect references, or coded language -> classify as 0 (no hate speech) with low confidence due to ambiguity"
    },
    {
      "text_to_annotate": "RT @JackPosobiec:  ",
      "uid": "fe657971-43f5-4369-9a70-ddf8bc92699f",
      "edge_case_id": 4.0,
      "pca_x": -0.6028523368519607,
      "pca_y": -0.18059424626112033,
      "raw_annotations": "{\n  \"analysis\": \"Step-by-step evaluation of ALL guideline criteria with text evidence:\\n\\n1. Assaults on Human Dignity: Checked for any content that demeans or degrades individuals or groups based on protected characteristics. The text is only 'RT @JackPosobiec:' with no additional content, so this criterion is NOT satisfied. No evidence present.\\n\\n2. Calls for Violence: Checked for any incitement or encouragement of physical harm or violence. The text contains no such content, so this criterion is NOT satisfied. No evidence present.\\n\\n3. Vulgarity and/or Offensive Language: Checked for profanity, slurs, or offensive language. The text contains none, so this criterion is NOT satisfied. No evidence present.\\n\\nThe text is essentially an incomplete or empty retweet with no substantive content to evaluate.\",\n  \"annotation\": \"-1\",\n  \"confidence\": 60,\n  \"new_edge_case\": true,\n  \"new_edge_case_rule\": \"When a post contains only a retweet handle or is otherwise contentless (e.g., 'RT @user:' with no additional text) -> refuse to classify (-1)\"\n}",
      "analyses": "Step-by-step evaluation of ALL guideline criteria with text evidence:\n\n1. Assaults on Human Dignity: Checked for any content that demeans or degrades individuals or groups based on protected characteristics. The text is only 'RT @JackPosobiec:' with no additional content, so this criterion is NOT satisfied. No evidence present.\n\n2. Calls for Violence: Checked for any incitement or encouragement of physical harm or violence. The text contains no such content, so this criterion is NOT satisfied. No evidence present.\n\n3. Vulgarity and/or Offensive Language: Checked for profanity, slurs, or offensive language. The text contains none, so this criterion is NOT satisfied. No evidence present.\n\nThe text is essentially an incomplete or empty retweet with no substantive content to evaluate.",
      "annotation": -1,
      "confidence": 60,
      "guideline_improvement": "when content lacks sufficient information for evaluation (e.g., URLs, non-text media, ambiguous language, or insufficient context) -> refuse to classify (-1)"
    },
    {
      "text_to_annotate": "You only have to look to South Africa to see how whites will be treated as a minority in a majority non-white country. Anyone who thinks it won't happen to us is kidding themselves. Anti-white rhetoric is already unprecedentedly high. The more who realise this the better.",
      "uid": "9f58179f-e316-4904-a904-196d53c68f76",
      "edge_case_id": 3.0,
      "pca_x": 0.1325716842404432,
      "pca_y": -0.025421474679583556,
      "raw_annotations": "{\n  \"analysis\": \"Step-by-step evaluation of ALL guideline criteria with text evidence:\\n\\n1. Assaults on Human Dignity:\\n- Guideline: Does the post demean or degrade individuals or groups based on race, ethnicity, gender, religion, sexual orientation, or other protected characteristics?\\n- Evaluation: The post discusses 'whites' as a group and suggests that they are or will be mistreated as a minority in a majority non-white country, referencing South Africa. The phrase 'how whites will be treated' implies negative treatment, and 'anti-white rhetoric is already unprecedentedly high' frames whites as victims of hostility. While the post does not use explicit slurs or direct demeaning language, it frames intergroup relations in a way that could be interpreted as stoking fear or resentment along racial lines. However, it does not directly demean or degrade non-white groups, but rather expresses concern for whites.\\n- Satisfied/Not Satisfied: Not fully satisfied for direct demeaning/degrading language, but the post does invoke racial group antagonism.\\n- Text Evidence: 'how whites will be treated as a minority in a majority non-white country', 'Anti-white rhetoric is already unprecedentedly high.'\\n\\n2. Calls for Violence:\\n- Guideline: Does the post incite or encourage physical harm or violence against individuals or groups?\\n- Evaluation: The post does not explicitly or implicitly call for violence or encourage physical harm against any group.\\n- Satisfied/Not Satisfied: Not satisfied.\\n- Text Evidence: No language inciting violence is present.\\n\\n3. Vulgarity and/or Offensive Language:\\n- Guideline: Does the post contain profanity, slurs, or other offensive language that may or may not be directed at individuals or groups?\\n- Evaluation: The post does not contain profanity, slurs, or overtly offensive language.\\n- Satisfied/Not Satisfied: Not satisfied.\\n- Text Evidence: No vulgar or offensive terms are used.\\n\\nSummary: The post expresses a racially charged viewpoint, suggesting that whites are or will be mistreated as minorities and that 'anti-white rhetoric' is high. While it does not use slurs, profanity, or directly demean non-white groups, it frames racial relations in a way that could be interpreted as stoking fear or resentment. However, per the guidelines, hate speech requires demeaning/degrading language, calls for violence, or offensive language. This post does not clearly meet those thresholds, though it is borderline.\",\n  \"annotation\": \"0\",\n  \"confidence\": 65,\n  \"new_edge_case\": true,\n  \"new_edge_case_rule\": \"When a post frames intergroup relations in a way that stokes fear or resentment but does not use explicit demeaning language, calls for violence, or offensive language -> classify as 0 (no hate speech) unless guidelines are updated to include implicit antagonism\"\n}",
      "analyses": "Step-by-step evaluation of ALL guideline criteria with text evidence:\n\n1. Assaults on Human Dignity:\n- Guideline: Does the post demean or degrade individuals or groups based on race, ethnicity, gender, religion, sexual orientation, or other protected characteristics?\n- Evaluation: The post discusses 'whites' as a group and suggests that they are or will be mistreated as a minority in a majority non-white country, referencing South Africa. The phrase 'how whites will be treated' implies negative treatment, and 'anti-white rhetoric is already unprecedentedly high' frames whites as victims of hostility. While the post does not use explicit slurs or direct demeaning language, it frames intergroup relations in a way that could be interpreted as stoking fear or resentment along racial lines. However, it does not directly demean or degrade non-white groups, but rather expresses concern for whites.\n- Satisfied/Not Satisfied: Not fully satisfied for direct demeaning/degrading language, but the post does invoke racial group antagonism.\n- Text Evidence: 'how whites will be treated as a minority in a majority non-white country', 'Anti-white rhetoric is already unprecedentedly high.'\n\n2. Calls for Violence:\n- Guideline: Does the post incite or encourage physical harm or violence against individuals or groups?\n- Evaluation: The post does not explicitly or implicitly call for violence or encourage physical harm against any group.\n- Satisfied/Not Satisfied: Not satisfied.\n- Text Evidence: No language inciting violence is present.\n\n3. Vulgarity and/or Offensive Language:\n- Guideline: Does the post contain profanity, slurs, or other offensive language that may or may not be directed at individuals or groups?\n- Evaluation: The post does not contain profanity, slurs, or overtly offensive language.\n- Satisfied/Not Satisfied: Not satisfied.\n- Text Evidence: No vulgar or offensive terms are used.\n\nSummary: The post expresses a racially charged viewpoint, suggesting that whites are or will be mistreated as minorities and that 'anti-white rhetoric' is high. While it does not use slurs, profanity, or directly demean non-white groups, it frames racial relations in a way that could be interpreted as stoking fear or resentment. However, per the guidelines, hate speech requires demeaning/degrading language, calls for violence, or offensive language. This post does not clearly meet those thresholds, though it is borderline.",
      "annotation": 0,
      "confidence": 65,
      "guideline_improvement": "when the post uses implicit antagonism, generalizations, or ambiguous framing without explicit demeaning language, calls for violence, or offensive targeting of protected groups -> classify as 0 (no hate speech)"
    },
    {
      "text_to_annotate": "You know, I would love to support companies like In-N-Out Burger and Chick-fil-A, but I don't want to get heart disease and die either.Â  Eat real food, White man, not the poison we are encouraged to eat at every turn.",
      "uid": "37a38fe6-fe32-47ac-92b1-311615e64feb",
      "edge_case_id": 1.0,
      "pca_x": 0.1803459201480277,
      "pca_y": 0.0255017586084543,
      "raw_annotations": "{\n  \"analysis\": \"1. Assaults on Human Dignity: This criterion checks for demeaning or degrading language based on protected characteristics such as race, ethnicity, gender, etc. The phrase 'Eat real food, White man, not the poison we are encouraged to eat at every turn.' specifically addresses 'White man' and implies that 'White men' are being targeted or advised in a negative context. While the statement is not overtly demeaning, it singles out a racial group in a way that could be interpreted as othering or making a negative generalization. However, the context is more about dietary choices than an explicit attack on dignity. \\n\\n2. Calls for Violence: This criterion checks for incitement or encouragement of physical harm. There is no language in the post that calls for or encourages violence against any individual or group. The mention of 'heart disease and die' refers to the speaker's own health concerns, not a threat or call for violence. \\n\\n3. Vulgarity and/or Offensive Language: This criterion checks for profanity, slurs, or other offensive language. The post does not contain profanity or slurs. The use of 'poison' is metaphorical and refers to unhealthy food, not as a slur or offensive term directed at a group. The phrase 'White man' is not a slur in itself, but its use in this context could be considered exclusionary or unnecessarily racialized, though not overtly offensive or vulgar.\",\n  \"annotation\": \"0\",\n  \"confidence\": 80,\n  \"new_edge_case\": true,\n  \"new_edge_case_rule\": \"When a post addresses a protected group in a non-overtly demeaning or offensive way, but the context is not clearly hateful or derogatory -> classify as 0 (no hate speech) unless explicit demeaning, violence, or slurs are present\"\n}",
      "analyses": "1. Assaults on Human Dignity: This criterion checks for demeaning or degrading language based on protected characteristics such as race, ethnicity, gender, etc. The phrase 'Eat real food, White man, not the poison we are encouraged to eat at every turn.' specifically addresses 'White man' and implies that 'White men' are being targeted or advised in a negative context. While the statement is not overtly demeaning, it singles out a racial group in a way that could be interpreted as othering or making a negative generalization. However, the context is more about dietary choices than an explicit attack on dignity. \n\n2. Calls for Violence: This criterion checks for incitement or encouragement of physical harm. There is no language in the post that calls for or encourages violence against any individual or group. The mention of 'heart disease and die' refers to the speaker's own health concerns, not a threat or call for violence. \n\n3. Vulgarity and/or Offensive Language: This criterion checks for profanity, slurs, or other offensive language. The post does not contain profanity or slurs. The use of 'poison' is metaphorical and refers to unhealthy food, not as a slur or offensive term directed at a group. The phrase 'White man' is not a slur in itself, but its use in this context could be considered exclusionary or unnecessarily racialized, though not overtly offensive or vulgar.",
      "annotation": 0,
      "confidence": 80,
      "guideline_improvement": "when the post references protected groups but lacks explicit assaults on dignity, calls for violence, or vulgarity/offensive language directed at them -> classify as 0 (no hate speech)"
    },
    {
      "text_to_annotate": "Is it time the Cowardly Police of Common Core faced OUR wrath?  https://gellerreport.com/2018/04/british-police-fear-muslim-rage.html/",
      "uid": "c5164883-dc82-4073-a1b0-10c3490c49ba",
      "edge_case_id": 0.0,
      "pca_x": 0.128189416008892,
      "pca_y": 0.017886887764539366,
      "raw_annotations": "{\n  \"analysis\": \"1. Assaults on Human Dignity: Checking for demeaning or degrading language based on protected characteristics. The phrase 'Cowardly Police of Common Core' is derogatory towards police, but 'police' is not a protected characteristic under the guideline. The linked article title references 'British police fear Muslim rage,' but the post itself does not directly demean a protected group. Not satisfied. Evidence: 'Cowardly Police of Common Core.'\\n\\n2. Calls for Violence: Checking for incitement or encouragement of physical harm. The phrase 'faced OUR wrath' could be interpreted as a call for action, but it is ambiguous whether this is a literal call for violence or a metaphorical expression of anger. No explicit call for violence is present. Not satisfied. Evidence: 'faced OUR wrath.'\\n\\n3. Vulgarity and/or Offensive Language: Checking for profanity, slurs, or offensive language. The word 'cowardly' is insulting but not a slur or profanity. No vulgar or offensive language directed at a protected group. Not satisfied. Evidence: 'Cowardly Police.'\",\n  \"annotation\": \"0\",\n  \"confidence\": 70,\n  \"new_edge_case\": true,\n  \"new_edge_case_rule\": \"When a post uses aggressive or hostile language toward non-protected groups (e.g., police) and contains ambiguous calls to action that are not explicit incitements to violence -> classify as 0 (no hate speech) unless further context clarifies intent\"\n}",
      "analyses": "1. Assaults on Human Dignity: Checking for demeaning or degrading language based on protected characteristics. The phrase 'Cowardly Police of Common Core' is derogatory towards police, but 'police' is not a protected characteristic under the guideline. The linked article title references 'British police fear Muslim rage,' but the post itself does not directly demean a protected group. Not satisfied. Evidence: 'Cowardly Police of Common Core.'\n\n2. Calls for Violence: Checking for incitement or encouragement of physical harm. The phrase 'faced OUR wrath' could be interpreted as a call for action, but it is ambiguous whether this is a literal call for violence or a metaphorical expression of anger. No explicit call for violence is present. Not satisfied. Evidence: 'faced OUR wrath.'\n\n3. Vulgarity and/or Offensive Language: Checking for profanity, slurs, or offensive language. The word 'cowardly' is insulting but not a slur or profanity. No vulgar or offensive language directed at a protected group. Not satisfied. Evidence: 'Cowardly Police.'",
      "annotation": 0,
      "confidence": 70,
      "guideline_improvement": "when the post targets non-protected groups, individuals, or characteristics (e.g., political groups, institutions, public figures) without explicit calls for violence or slurs targeting protected groups -> classify as 0 (no hate speech)"
    },
    {
      "text_to_annotate": "I was thinking that maybe legalizing it would enable people like incels to fulfill their own reasonsÂ  on women .there are many weirdos like them out there ... That's all nothing cuck about it...",
      "uid": "7b72b5be-c1c7-449d-bafb-7c351dc692d8",
      "edge_case_id": 8.0,
      "pca_x": 0.033702145506535275,
      "pca_y": 0.2666525964746318,
      "raw_annotations": "{\n  \"analysis\": \"1. Assaults on Human Dignity: Checking if the post demeans or degrades individuals or groups based on protected characteristics. The post refers to 'incels' and 'weirdos' and discusses 'fulfill their own reasons on women.' The term 'incels' is often used pejoratively, but it is not a protected characteristic. The phrase 'fulfill their own reasons on women' is ambiguous and could be interpreted as objectifying or demeaning women, but it is not explicit. The post does not directly demean or degrade women or any protected group in a clear, explicit way. \\n\\n2. Calls for Violence: Checking for incitement or encouragement of physical harm or violence. The post does not explicitly call for violence or encourage harm against any group or individual. The phrase 'fulfill their own reasons on women' is vague and could be interpreted as problematic, but it does not directly incite violence. \\n\\n3. Vulgarity and/or Offensive Language: Checking for profanity, slurs, or offensive language. The post uses the term 'cuck,' which is a derogatory slang term, and 'weirdos,' which is pejorative but not a slur. 'Cuck' is often used as an insult in online discourse, but in this context, the author says 'nothing cuck about it,' which is a denial rather than a direct insult. There is no explicit profanity or slur directed at a protected group.\",\n  \"annotation\": \"0\",\n  \"confidence\": 70,\n  \"new_edge_case\": true,\n  \"new_edge_case_rule\": \"When a post contains ambiguous or indirect references that could be interpreted as demeaning or objectifying a protected group, but lacks explicit language or clear intent, and does not meet the threshold for hate speech per guidelines -> classify as 0 with low confidence\"\n}",
      "analyses": "1. Assaults on Human Dignity: Checking if the post demeans or degrades individuals or groups based on protected characteristics. The post refers to 'incels' and 'weirdos' and discusses 'fulfill their own reasons on women.' The term 'incels' is often used pejoratively, but it is not a protected characteristic. The phrase 'fulfill their own reasons on women' is ambiguous and could be interpreted as objectifying or demeaning women, but it is not explicit. The post does not directly demean or degrade women or any protected group in a clear, explicit way. \n\n2. Calls for Violence: Checking for incitement or encouragement of physical harm or violence. The post does not explicitly call for violence or encourage harm against any group or individual. The phrase 'fulfill their own reasons on women' is vague and could be interpreted as problematic, but it does not directly incite violence. \n\n3. Vulgarity and/or Offensive Language: Checking for profanity, slurs, or offensive language. The post uses the term 'cuck,' which is a derogatory slang term, and 'weirdos,' which is pejorative but not a slur. 'Cuck' is often used as an insult in online discourse, but in this context, the author says 'nothing cuck about it,' which is a denial rather than a direct insult. There is no explicit profanity or slur directed at a protected group.",
      "annotation": 0,
      "confidence": 70,
      "guideline_improvement": "when content lacks explicit evidence of demeaning language, calls for violence, or offensive slurs targeting protected characteristics, despite potential ambiguity, sarcasm, indirect references, or coded language -> classify as 0 (no hate speech) with low confidence due to ambiguity"
    },
    {
      "text_to_annotate": "How to spot a scumbag: 1.Â  George Soros sings his praises. https://archive.fo/ov5J5",
      "uid": "d80465d9-429c-4a8c-b884-acff927a0472",
      "edge_case_id": 0.0,
      "pca_x": 0.16968812739633415,
      "pca_y": -0.09825710100388449,
      "raw_annotations": "{\n  \"analysis\": \"1. Assaults on Human Dignity: The post uses the term 'scumbag,' a derogatory insult, and links it to 'George Soros sings his praises.' George Soros is a real individual who is often the subject of conspiracy theories and hate speech, frequently with antisemitic undertones. However, in this post, the insult is not directly applied to Soros but to an unspecified person or group who is praised by Soros. The post does not explicitly mention any protected characteristic (race, ethnicity, religion, etc.), but the context of Soros as a figure often targeted in antisemitic discourse is relevant. Still, the text itself does not directly demean a protected group, only associates being praised by Soros with being a 'scumbag.'\\n\\n2. Calls for Violence: There is no incitement or encouragement of physical harm or violence in the post. No language suggests or encourages violence against any individual or group. Example: 'How to spot a scumbag: 1. George Soros sings his praises.'\\n\\n3. Vulgarity and/or Offensive Language: The term 'scumbag' is vulgar and offensive. It is used as a general insult, not a slur targeting a protected characteristic, but it is still offensive language. Example: 'scumbag.'\\n\\nSummary: The post uses offensive language ('scumbag') and references George Soros in a negative context, which may have dog-whistle implications, but does not explicitly attack a protected group or call for violence. The offensive language is not a slur nor is it clearly hate speech per the guideline, unless the context of Soros as a Jewish individual is considered sufficient for an implicit attack, which is not explicit in the text.\",\n  \"annotation\": \"0\",\n  \"confidence\": 70,\n  \"new_edge_case\": true,\n  \"new_edge_case_rule\": \"When a post uses offensive language and references a public figure commonly targeted in hate speech, but does not explicitly attack a protected group or call for violence -> classify as not hate speech (0) unless explicit evidence is present\"\n}",
      "analyses": "1. Assaults on Human Dignity: The post uses the term 'scumbag,' a derogatory insult, and links it to 'George Soros sings his praises.' George Soros is a real individual who is often the subject of conspiracy theories and hate speech, frequently with antisemitic undertones. However, in this post, the insult is not directly applied to Soros but to an unspecified person or group who is praised by Soros. The post does not explicitly mention any protected characteristic (race, ethnicity, religion, etc.), but the context of Soros as a figure often targeted in antisemitic discourse is relevant. Still, the text itself does not directly demean a protected group, only associates being praised by Soros with being a 'scumbag.'\n\n2. Calls for Violence: There is no incitement or encouragement of physical harm or violence in the post. No language suggests or encourages violence against any individual or group. Example: 'How to spot a scumbag: 1. George Soros sings his praises.'\n\n3. Vulgarity and/or Offensive Language: The term 'scumbag' is vulgar and offensive. It is used as a general insult, not a slur targeting a protected characteristic, but it is still offensive language. Example: 'scumbag.'\n\nSummary: The post uses offensive language ('scumbag') and references George Soros in a negative context, which may have dog-whistle implications, but does not explicitly attack a protected group or call for violence. The offensive language is not a slur nor is it clearly hate speech per the guideline, unless the context of Soros as a Jewish individual is considered sufficient for an implicit attack, which is not explicit in the text.",
      "annotation": 0,
      "confidence": 70,
      "guideline_improvement": "when the post targets non-protected groups, individuals, or characteristics (e.g., political groups, institutions, public figures) without explicit calls for violence or slurs targeting protected groups -> classify as 0 (no hate speech)"
    },
    {
      "text_to_annotate": "openly calling for violence and murder, I suggest you learn how to spell gun before you get one. ",
      "uid": "ff630060-c1e3-4587-bcb6-05d88167bfd8",
      "edge_case_id": 2.0,
      "pca_x": 0.14440477877919938,
      "pca_y": -0.1481734473624147,
      "raw_annotations": "{\n  \"analysis\": \"1. Assaults on Human Dignity: Checking if the post demeans or degrades individuals or groups based on protected characteristics. There is no explicit mention of race, ethnicity, gender, religion, sexual orientation, or other protected characteristics. Therefore, this criterion is NOT satisfied. No relevant text evidence found. \\n2. Calls for Violence: Checking if the post incites or encourages physical harm or violence. The phrase 'openly calling for violence and murder' references violence, but it is not clear if the author is themselves calling for violence or referencing someone else's actions. The second sentence, 'I suggest you learn how to spell gun before you get one,' could be interpreted as a taunt or as sarcasm, but does not directly incite violence. Therefore, this criterion is NOT clearly satisfied. \\n3. Vulgarity and/or Offensive Language: Checking for profanity, slurs, or other offensive language. The post contains a taunt ('I suggest you learn how to spell gun before you get one'), which is mocking but does not contain profanity or slurs. Therefore, this criterion is NOT satisfied.\",\n  \"annotation\": \"0\",\n  \"confidence\": 70,\n  \"new_edge_case\": true,\n  \"new_edge_case_rule\": \"When a post references violence or murder but does not itself incite, endorse, or direct violence, and lacks protected characteristic targeting or explicit offensive language -> classify as 0 (no hate speech)\"\n}",
      "analyses": "1. Assaults on Human Dignity: Checking if the post demeans or degrades individuals or groups based on protected characteristics. There is no explicit mention of race, ethnicity, gender, religion, sexual orientation, or other protected characteristics. Therefore, this criterion is NOT satisfied. No relevant text evidence found. \n2. Calls for Violence: Checking if the post incites or encourages physical harm or violence. The phrase 'openly calling for violence and murder' references violence, but it is not clear if the author is themselves calling for violence or referencing someone else's actions. The second sentence, 'I suggest you learn how to spell gun before you get one,' could be interpreted as a taunt or as sarcasm, but does not directly incite violence. Therefore, this criterion is NOT clearly satisfied. \n3. Vulgarity and/or Offensive Language: Checking for profanity, slurs, or other offensive language. The post contains a taunt ('I suggest you learn how to spell gun before you get one'), which is mocking but does not contain profanity or slurs. Therefore, this criterion is NOT satisfied.",
      "annotation": 0,
      "confidence": 70,
      "guideline_improvement": "when the post contains references to violence, threats, or aggressive language without inciting harm against protected groups or using explicit hate speech elements -> classify as 0 (no hate speech)"
    },
    {
      "text_to_annotate": "https://www.youtube.com/watch?v=ICuiwl0mXhQ  ",
      "uid": "8dd35e5a-4a60-4a05-b491-5e439e41426f",
      "edge_case_id": 4.0,
      "pca_x": -0.668387623245958,
      "pca_y": -0.2109028996714758,
      "raw_annotations": "{\n  \"analysis\": \"Step-by-step evaluation of ALL guideline criteria with text evidence:\\n\\n1. Assaults on Human Dignity: The post consists solely of a YouTube URL (https://www.youtube.com/watch?v=ICuiwl0mXhQ). There is no textual content present that can be evaluated for demeaning or degrading language toward individuals or groups. Guideline not satisfied. Evidence: No text beyond the URL.\\n\\n2. Calls for Violence: There is no text in the post that could incite or encourage violence, as the only content is a URL. Guideline not satisfied. Evidence: No text beyond the URL.\\n\\n3. Vulgarity and/or Offensive Language: There is no profanity, slurs, or offensive language present, as the post contains only a URL. Guideline not satisfied. Evidence: No text beyond the URL.\\n\\nNo aspect of the post can be evaluated for hate speech based on the provided guidelines, as there is no evaluable textual content.\",\n  \"annotation\": \"-1\",\n  \"confidence\": 70,\n  \"new_edge_case\": true,\n  \"new_edge_case_rule\": \"When a post contains only a URL or non-textual content with no evaluable text -> refuse to classify (-1)\"\n}",
      "analyses": "Step-by-step evaluation of ALL guideline criteria with text evidence:\n\n1. Assaults on Human Dignity: The post consists solely of a YouTube URL (https://www.youtube.com/watch?v=ICuiwl0mXhQ). There is no textual content present that can be evaluated for demeaning or degrading language toward individuals or groups. Guideline not satisfied. Evidence: No text beyond the URL.\n\n2. Calls for Violence: There is no text in the post that could incite or encourage violence, as the only content is a URL. Guideline not satisfied. Evidence: No text beyond the URL.\n\n3. Vulgarity and/or Offensive Language: There is no profanity, slurs, or offensive language present, as the post contains only a URL. Guideline not satisfied. Evidence: No text beyond the URL.\n\nNo aspect of the post can be evaluated for hate speech based on the provided guidelines, as there is no evaluable textual content.",
      "annotation": -1,
      "confidence": 70,
      "guideline_improvement": "when content lacks sufficient information for evaluation (e.g., URLs, non-text media, ambiguous language, or insufficient context) -> refuse to classify (-1)"
    },
    {
      "text_to_annotate": "To the human Catholic clergy You damn fools to allow this to happen Homosexuals The smoke of Satan Misanthrope",
      "uid": "4ea1c46d-ce24-4918-9375-5e1a0757a745",
      "edge_case_id": 8.0,
      "pca_x": -0.02249151851299777,
      "pca_y": 0.3024873286350386,
      "raw_annotations": "{\n  \"analysis\": \"1. Assaults on Human Dignity: The post references 'the human Catholic clergy' and 'Homosexuals' in a negative context. The phrase 'You damn fools to allow this to happen' is directed at the Catholic clergy, which is a group defined by religion. The term 'Homosexuals' is mentioned without explicit derogatory language, but the context is ambiguous as to whether it is being used pejoratively or simply referenced. The phrase 'The smoke of Satan' is a historically loaded term sometimes used in religious contexts to demonize certain groups or behaviors, potentially implying that 'Homosexuals' are associated with evil, but this is not explicitly stated. The word 'Misanthrope' (a person who dislikes humankind) is included without clear referent. Overall, there is a suggestion of demeaning language toward the clergy and possibly toward homosexuals, but the connection is not explicit enough to definitively satisfy this criterion. \\n2. Calls for Violence: There is no explicit or implicit call for violence in the text. No language incites or encourages physical harm. \\n3. Vulgarity and/or Offensive Language: The phrase 'You damn fools' contains mild profanity directed at the clergy, which could be considered offensive language. However, it is not a slur or severe profanity. The rest of the language ('Homosexuals', 'The smoke of Satan', 'Misanthrope') is not inherently vulgar, but may be offensive depending on context, which is not fully clear here.\",\n  \"annotation\": \"0\",\n  \"confidence\": 65,\n  \"new_edge_case\": true,\n  \"new_edge_case_rule\": \"When a post contains ambiguous references to protected groups and potentially offensive language, but lacks explicit demeaning, violent, or slur content, and the target or intent is unclear -> classify as 0 with low confidence\"\n}",
      "analyses": "1. Assaults on Human Dignity: The post references 'the human Catholic clergy' and 'Homosexuals' in a negative context. The phrase 'You damn fools to allow this to happen' is directed at the Catholic clergy, which is a group defined by religion. The term 'Homosexuals' is mentioned without explicit derogatory language, but the context is ambiguous as to whether it is being used pejoratively or simply referenced. The phrase 'The smoke of Satan' is a historically loaded term sometimes used in religious contexts to demonize certain groups or behaviors, potentially implying that 'Homosexuals' are associated with evil, but this is not explicitly stated. The word 'Misanthrope' (a person who dislikes humankind) is included without clear referent. Overall, there is a suggestion of demeaning language toward the clergy and possibly toward homosexuals, but the connection is not explicit enough to definitively satisfy this criterion. \n2. Calls for Violence: There is no explicit or implicit call for violence in the text. No language incites or encourages physical harm. \n3. Vulgarity and/or Offensive Language: The phrase 'You damn fools' contains mild profanity directed at the clergy, which could be considered offensive language. However, it is not a slur or severe profanity. The rest of the language ('Homosexuals', 'The smoke of Satan', 'Misanthrope') is not inherently vulgar, but may be offensive depending on context, which is not fully clear here.",
      "annotation": 0,
      "confidence": 65,
      "guideline_improvement": "when content lacks explicit evidence of demeaning language, calls for violence, or offensive slurs targeting protected characteristics, despite potential ambiguity, sarcasm, indirect references, or coded language -> classify as 0 (no hate speech) with low confidence due to ambiguity"
    },
    {
      "text_to_annotate": "The last paragraph of this Delingpole article states; 'Of course we know that the way liberals think is stupid and wrong. But surely weâ€™re not so harsh as to believe that the punishment for their mental illness should be death?' That is debatable. In a longer article about this event, it comes out that this couple were menaced repeatedly, and almost robbed in that region of the world. So, they k...",
      "uid": "cd359efd-8fb2-43c5-8a07-3ea9364ca8e2",
      "edge_case_id": 0.0,
      "pca_x": 0.0743607774690061,
      "pca_y": -0.22658808963832464,
      "raw_annotations": "{\n  \"analysis\": \"Step-by-step evaluation of ALL guideline criteria with text evidence:\\n\\n1. Assaults on Human Dignity: \\n- Guideline: Does the post demean or degrade individuals or groups based on race, ethnicity, gender, religion, sexual orientation, or other protected characteristics?\\n- Evaluation: The post references a quote from a Delingpole article: 'the way liberals think is stupid and wrong' and refers to 'the punishment for their mental illness.' This language degrades 'liberals' by calling their thinking 'stupid and wrong' and equating their beliefs to 'mental illness.' However, 'liberals' as a political group are not explicitly listed among protected characteristics in the guideline (race, ethnicity, gender, religion, sexual orientation, or other protected characteristics). Unless 'other protected characteristics' is interpreted to include political affiliation, this may not strictly satisfy the criterion.\\n\\n2. Calls for Violence:\\n- Guideline: Does the post incite or encourage physical harm or violence against individuals or groups?\\n- Evaluation: The quoted text says, 'But surely weâ€™re not so harsh as to believe that the punishment for their mental illness should be death?' and then 'That is debatable.' The phrase 'That is debatable' after referencing death as a punishment for 'liberals' could be interpreted as entertaining or not outright rejecting the idea of violence, but it does not directly incite or encourage violence. The post does not explicitly call for violence.\\n\\n3. Vulgarity and/or Offensive Language:\\n- Guideline: Does the post contain profanity, slurs, or other offensive language that may or may not be directed at individuals or groups?\\n- Evaluation: The phrase 'the way liberals think is stupid and wrong' and 'mental illness' used to describe a political group is offensive and demeaning, but does not contain profanity or slurs in the traditional sense. The language is derogatory but not profane.\\n\\nSummary: The post contains derogatory and demeaning language about 'liberals,' equating their beliefs to 'mental illness' and suggesting that death as a punishment is 'debatable.' While this is offensive and arguably hateful, the guidelines do not explicitly include political affiliation as a protected characteristic. There is no direct call for violence, but the post flirts with the idea. The language is offensive but not profane.\",\n  \"annotation\": \"0\",\n  \"confidence\": 60,\n  \"new_edge_case\": true,\n  \"new_edge_case_rule\": \"When a post contains demeaning or violent language targeting political affiliation (not explicitly listed as a protected characteristic) -> classify as 0 unless guidelines are updated to include political groups\"\n}",
      "analyses": "Step-by-step evaluation of ALL guideline criteria with text evidence:\n\n1. Assaults on Human Dignity: \n- Guideline: Does the post demean or degrade individuals or groups based on race, ethnicity, gender, religion, sexual orientation, or other protected characteristics?\n- Evaluation: The post references a quote from a Delingpole article: 'the way liberals think is stupid and wrong' and refers to 'the punishment for their mental illness.' This language degrades 'liberals' by calling their thinking 'stupid and wrong' and equating their beliefs to 'mental illness.' However, 'liberals' as a political group are not explicitly listed among protected characteristics in the guideline (race, ethnicity, gender, religion, sexual orientation, or other protected characteristics). Unless 'other protected characteristics' is interpreted to include political affiliation, this may not strictly satisfy the criterion.\n\n2. Calls for Violence:\n- Guideline: Does the post incite or encourage physical harm or violence against individuals or groups?\n- Evaluation: The quoted text says, 'But surely weâ€™re not so harsh as to believe that the punishment for their mental illness should be death?' and then 'That is debatable.' The phrase 'That is debatable' after referencing death as a punishment for 'liberals' could be interpreted as entertaining or not outright rejecting the idea of violence, but it does not directly incite or encourage violence. The post does not explicitly call for violence.\n\n3. Vulgarity and/or Offensive Language:\n- Guideline: Does the post contain profanity, slurs, or other offensive language that may or may not be directed at individuals or groups?\n- Evaluation: The phrase 'the way liberals think is stupid and wrong' and 'mental illness' used to describe a political group is offensive and demeaning, but does not contain profanity or slurs in the traditional sense. The language is derogatory but not profane.\n\nSummary: The post contains derogatory and demeaning language about 'liberals,' equating their beliefs to 'mental illness' and suggesting that death as a punishment is 'debatable.' While this is offensive and arguably hateful, the guidelines do not explicitly include political affiliation as a protected characteristic. There is no direct call for violence, but the post flirts with the idea. The language is offensive but not profane.",
      "annotation": 0,
      "confidence": 60,
      "guideline_improvement": "when the post targets non-protected groups, individuals, or characteristics (e.g., political groups, institutions, public figures) without explicit calls for violence or slurs targeting protected groups -> classify as 0 (no hate speech)"
    },
    {
      "text_to_annotate": "Everyone accuses the US of being 'Imperialistic'. Nonsense. China wants to rule the world. Vlad Putin wants to rule the world. Great Britain wanted to rule the world. France wanted to rule the world. Germany, the Soviet Union, Spain, even Islam, wanted to rule the world. The United States doesn't even want to rule Canada!",
      "uid": "4f06faf6-2e24-495c-a25f-927b7c9a1858",
      "edge_case_id": 7.0,
      "pca_x": 0.11881137958076876,
      "pca_y": -0.057369003219535336,
      "raw_annotations": "{\n  \"analysis\": \"Step-by-step evaluation of ALL guideline criteria with text evidence:\\n\\n1. Assaults on Human Dignity:\\n- Guideline: Does the post demean or degrade individuals or groups based on race, ethnicity, gender, religion, sexual orientation, or other protected characteristics?\\n- Evaluation: The post lists several countries and 'Islam' as entities that 'wanted to rule the world.' The mention of 'Islam' is notable because it is a religion, not a country. The statement 'even Islam, wanted to rule the world' could be interpreted as attributing imperialistic ambitions to an entire religion, which may be seen as demeaning or stereotyping a protected group based on religion. However, the tone is more historical and comparative, and does not use overtly demeaning or degrading language. The other entities mentioned are countries or political leaders, not protected characteristics.\\n\\n2. Calls for Violence:\\n- Guideline: Does the post incite or encourage physical harm or violence against individuals or groups?\\n- Evaluation: There is no language in the post that incites or encourages violence. The post is making a comparative statement about historical or perceived ambitions of various entities.\\n\\n3. Vulgarity and/or Offensive Language:\\n- Guideline: Does the post contain profanity, slurs, or other offensive language that may or may not be directed at individuals or groups?\\n- Evaluation: The post does not contain profanity or slurs. The language is not overtly offensive, though the inclusion of 'Islam' in a list of countries could be considered insensitive or offensive to some, as it conflates a religion with nation-states and attributes negative motives to it.\\n\\nSummary: The only potentially problematic aspect is the inclusion of 'Islam' in a list of countries with imperial ambitions, which could be seen as stereotyping a religion. However, the post does not use demeaning, degrading, or explicitly hateful language, nor does it call for violence or use slurs.\",\n  \"annotation\": \"0\",\n  \"confidence\": 75,\n  \"new_edge_case\": true,\n  \"new_edge_case_rule\": \"When a post attributes negative motives or ambitions to a religion in a comparative or historical context without explicit demeaning language or calls for violence -> classify as not hate speech (0) but flag for potential insensitivity\"\n}",
      "analyses": "Step-by-step evaluation of ALL guideline criteria with text evidence:\n\n1. Assaults on Human Dignity:\n- Guideline: Does the post demean or degrade individuals or groups based on race, ethnicity, gender, religion, sexual orientation, or other protected characteristics?\n- Evaluation: The post lists several countries and 'Islam' as entities that 'wanted to rule the world.' The mention of 'Islam' is notable because it is a religion, not a country. The statement 'even Islam, wanted to rule the world' could be interpreted as attributing imperialistic ambitions to an entire religion, which may be seen as demeaning or stereotyping a protected group based on religion. However, the tone is more historical and comparative, and does not use overtly demeaning or degrading language. The other entities mentioned are countries or political leaders, not protected characteristics.\n\n2. Calls for Violence:\n- Guideline: Does the post incite or encourage physical harm or violence against individuals or groups?\n- Evaluation: There is no language in the post that incites or encourages violence. The post is making a comparative statement about historical or perceived ambitions of various entities.\n\n3. Vulgarity and/or Offensive Language:\n- Guideline: Does the post contain profanity, slurs, or other offensive language that may or may not be directed at individuals or groups?\n- Evaluation: The post does not contain profanity or slurs. The language is not overtly offensive, though the inclusion of 'Islam' in a list of countries could be considered insensitive or offensive to some, as it conflates a religion with nation-states and attributes negative motives to it.\n\nSummary: The only potentially problematic aspect is the inclusion of 'Islam' in a list of countries with imperial ambitions, which could be seen as stereotyping a religion. However, the post does not use demeaning, degrading, or explicitly hateful language, nor does it call for violence or use slurs.",
      "annotation": 0,
      "confidence": 75,
      "guideline_improvement": "when content reports offensive material or uses insensitive language without direct targeting of protected groups -> classify as no hate speech (0) but flag for review/insensitivity"
    },
    {
      "text_to_annotate": "Also, pretty sure that's a dude.",
      "uid": "c74007d8-313b-47ef-ac78-8345a6952217",
      "edge_case_id": 4.0,
      "pca_x": -0.28707721237627015,
      "pca_y": 0.12412962117993648,
      "raw_annotations": "{\n  \"analysis\": \"1. Assaults on Human Dignity: This criterion checks if the post demeans or degrades individuals or groups based on protected characteristics (e.g., gender, sexual orientation). The phrase 'Also, pretty sure that's a dude.' could be interpreted as questioning someone's gender identity, which may be demeaning in certain contexts, especially if directed at a transgender or non-binary individual. However, without additional context (e.g., who is being referred to, intent, or prior conversation), it is not possible to definitively determine if this is an assault on human dignity. Evidence: 'pretty sure that's a dude.'\\n2. Calls for Violence: There is no incitement or encouragement of physical harm or violence in the text. Not satisfied. Evidence: No language suggesting violence.\\n3. Vulgarity and/or Offensive Language: The post does not contain profanity, slurs, or explicitly offensive language. The term 'dude' is informal but not inherently offensive. Not satisfied. Evidence: No vulgar or offensive terms present.\",\n  \"annotation\": \"-1\",\n  \"confidence\": 60,\n  \"new_edge_case\": true,\n  \"new_edge_case_rule\": \"When a post ambiguously references a protected characteristic (e.g., gender) without clear context or explicit demeaning intent -> refuse to classify (-1)\"\n}",
      "analyses": "1. Assaults on Human Dignity: This criterion checks if the post demeans or degrades individuals or groups based on protected characteristics (e.g., gender, sexual orientation). The phrase 'Also, pretty sure that's a dude.' could be interpreted as questioning someone's gender identity, which may be demeaning in certain contexts, especially if directed at a transgender or non-binary individual. However, without additional context (e.g., who is being referred to, intent, or prior conversation), it is not possible to definitively determine if this is an assault on human dignity. Evidence: 'pretty sure that's a dude.'\n2. Calls for Violence: There is no incitement or encouragement of physical harm or violence in the text. Not satisfied. Evidence: No language suggesting violence.\n3. Vulgarity and/or Offensive Language: The post does not contain profanity, slurs, or explicitly offensive language. The term 'dude' is informal but not inherently offensive. Not satisfied. Evidence: No vulgar or offensive terms present.",
      "annotation": -1,
      "confidence": 60,
      "guideline_improvement": "when content lacks sufficient information for evaluation (e.g., URLs, non-text media, ambiguous language, or insufficient context) -> refuse to classify (-1)"
    },
    {
      "text_to_annotate": "See - told you: When â€œWakandan-Americansâ€ find out black panther was created by white menÂ   https://twitter.com/AbareKiller_/status/958380961053511680",
      "uid": "91c5ee2c-10e2-4e3f-baeb-bb0d6c65ddba",
      "edge_case_id": 8.0,
      "pca_x": 0.13024824597556844,
      "pca_y": 0.1653995976018918,
      "raw_annotations": "{\n  \"analysis\": \"1. Assaults on Human Dignity: This criterion checks for demeaning or degrading language targeting individuals or groups based on protected characteristics. The post uses the term 'Wakandan-Americans,' which is a fictional reference (from the Black Panther universe) and not a real-world group. However, the context is about Black Panther, a film significant to Black audiences, and the phrase could be interpreted as a veiled reference to Black Americans. The post appears to mock or belittle the reaction of 'Wakandan-Americans' (i.e., Black fans) upon learning that the character was created by white men. This could be seen as demeaning, but the language is indirect and relies on sarcasm rather than explicit degradation. Evidence: 'See - told you: When â€œWakandan-Americansâ€ find out black panther was created by white men.'\\n\\n2. Calls for Violence: There is no incitement or encouragement of physical harm or violence in the post. Evidence: No language in the post calls for or suggests violence.\\n\\n3. Vulgarity and/or Offensive Language: The post does not contain profanity, slurs, or overtly offensive language. The tone is mocking, but not explicitly vulgar or profane. Evidence: No slurs or profanity present.\\n\\nSummary: The post uses sarcasm and a fictional label to potentially mock a group (Black fans of Black Panther), but does not use explicit hate speech, slurs, or calls for violence. The demeaning aspect is subtle and indirect.\",\n  \"annotation\": \"0\",\n  \"confidence\": 70,\n  \"new_edge_case\": true,\n  \"new_edge_case_rule\": \"When a post uses fictional or indirect references to real-world protected groups in a mocking or sarcastic manner, but without explicit slurs, vulgarity, or calls for violence, and the demeaning aspect is ambiguous -> classify as 0 (no hate speech) with low confidence\"\n}",
      "analyses": "1. Assaults on Human Dignity: This criterion checks for demeaning or degrading language targeting individuals or groups based on protected characteristics. The post uses the term 'Wakandan-Americans,' which is a fictional reference (from the Black Panther universe) and not a real-world group. However, the context is about Black Panther, a film significant to Black audiences, and the phrase could be interpreted as a veiled reference to Black Americans. The post appears to mock or belittle the reaction of 'Wakandan-Americans' (i.e., Black fans) upon learning that the character was created by white men. This could be seen as demeaning, but the language is indirect and relies on sarcasm rather than explicit degradation. Evidence: 'See - told you: When â€œWakandan-Americansâ€ find out black panther was created by white men.'\n\n2. Calls for Violence: There is no incitement or encouragement of physical harm or violence in the post. Evidence: No language in the post calls for or suggests violence.\n\n3. Vulgarity and/or Offensive Language: The post does not contain profanity, slurs, or overtly offensive language. The tone is mocking, but not explicitly vulgar or profane. Evidence: No slurs or profanity present.\n\nSummary: The post uses sarcasm and a fictional label to potentially mock a group (Black fans of Black Panther), but does not use explicit hate speech, slurs, or calls for violence. The demeaning aspect is subtle and indirect.",
      "annotation": 0,
      "confidence": 70,
      "guideline_improvement": "when content lacks explicit evidence of demeaning language, calls for violence, or offensive slurs targeting protected characteristics, despite potential ambiguity, sarcasm, indirect references, or coded language -> classify as 0 (no hate speech) with low confidence due to ambiguity"
    },
    {
      "text_to_annotate": "F- ",
      "uid": "631f88d7-756e-40d2-9eb9-bf31550322a0",
      "edge_case_id": 4.0,
      "pca_x": -0.3979444103992584,
      "pca_y": 0.14515411668778358,
      "raw_annotations": "{\n  \"analysis\": \"1. Assaults on Human Dignity: The guideline asks if the post demeans or degrades individuals or groups based on protected characteristics. The text 'F-' does not reference any individual or group, nor does it mention any protected characteristic. Therefore, this criterion is NOT satisfied. Evidence: The text is simply 'F-'.\\n2. Calls for Violence: The guideline asks if the post incites or encourages physical harm or violence. There is no language in 'F-' that suggests violence or incitement. Therefore, this criterion is NOT satisfied. Evidence: The text is simply 'F-'.\\n3. Vulgarity and/or Offensive Language: The guideline asks if the post contains profanity, slurs, or other offensive language. 'F-' is an incomplete expression and could be interpreted as the beginning of a vulgar word (e.g., 'fuck'), but as written, it is not a complete profanity or slur. It is ambiguous whether this is intended as offensive language, as it is not explicit. Therefore, this criterion is NOT satisfied, but there is ambiguity. Evidence: The text is 'F-', which is not a complete offensive word.\",\n  \"annotation\": \"-1\",\n  \"confidence\": 60,\n  \"new_edge_case\": true,\n  \"new_edge_case_rule\": \"When a post contains an incomplete or ambiguous fragment that could be interpreted as offensive language but lacks explicit evidence -> refuse to classify (-1)\"\n}",
      "analyses": "1. Assaults on Human Dignity: The guideline asks if the post demeans or degrades individuals or groups based on protected characteristics. The text 'F-' does not reference any individual or group, nor does it mention any protected characteristic. Therefore, this criterion is NOT satisfied. Evidence: The text is simply 'F-'.\n2. Calls for Violence: The guideline asks if the post incites or encourages physical harm or violence. There is no language in 'F-' that suggests violence or incitement. Therefore, this criterion is NOT satisfied. Evidence: The text is simply 'F-'.\n3. Vulgarity and/or Offensive Language: The guideline asks if the post contains profanity, slurs, or other offensive language. 'F-' is an incomplete expression and could be interpreted as the beginning of a vulgar word (e.g., 'fuck'), but as written, it is not a complete profanity or slur. It is ambiguous whether this is intended as offensive language, as it is not explicit. Therefore, this criterion is NOT satisfied, but there is ambiguity. Evidence: The text is 'F-', which is not a complete offensive word.",
      "annotation": -1,
      "confidence": 60,
      "guideline_improvement": "when content lacks sufficient information for evaluation (e.g., URLs, non-text media, ambiguous language, or insufficient context) -> refuse to classify (-1)"
    },
    {
      "text_to_annotate": "These idiots are funding their own demise #Paristan is burning",
      "uid": "c9c03e7c-30a5-4d94-861a-f32ba3fc2faf",
      "edge_case_id": 8.0,
      "pca_x": 0.08454793679530448,
      "pca_y": 0.09841883647636931,
      "raw_annotations": "{\n  \"analysis\": \"1. Assaults on Human Dignity: The post uses the term 'idiots' to refer to a group, which is a demeaning term. However, it is not explicitly clear which protected characteristic (race, ethnicity, gender, religion, sexual orientation, etc.) the group is being targeted for. The hashtag '#Paristan' could be a reference to a group or place, but without further context, it is ambiguous whether it refers to a protected group. Evidence: 'These idiots are funding their own demise #Paristan is burning.'\\n\\n2. Calls for Violence: The post does not directly incite or encourage physical harm or violence. The phrase 'is burning' could be metaphorical or literal, but there is no explicit call for violence. Evidence: No direct incitement or encouragement of violence present.\\n\\n3. Vulgarity and/or Offensive Language: The word 'idiots' is an insult and offensive language, but it is not a slur or profanity. It is not a hate term per se, but it is derogatory. Evidence: 'idiots.'\\n\\nSummary: The post contains offensive language ('idiots') and references a group or place (#Paristan), but it does not clearly target a protected characteristic, nor does it call for violence or use hate slurs.\",\n  \"annotation\": \"0\",\n  \"confidence\": 70,\n  \"new_edge_case\": true,\n  \"new_edge_case_rule\": \"When a post uses derogatory language toward a group identified only by a hashtag or ambiguous reference, and there is no clear evidence of targeting a protected characteristic or explicit call for violence, but the language is offensive -> classify as 0 (no hate speech) with low confidence\"\n}",
      "analyses": "1. Assaults on Human Dignity: The post uses the term 'idiots' to refer to a group, which is a demeaning term. However, it is not explicitly clear which protected characteristic (race, ethnicity, gender, religion, sexual orientation, etc.) the group is being targeted for. The hashtag '#Paristan' could be a reference to a group or place, but without further context, it is ambiguous whether it refers to a protected group. Evidence: 'These idiots are funding their own demise #Paristan is burning.'\n\n2. Calls for Violence: The post does not directly incite or encourage physical harm or violence. The phrase 'is burning' could be metaphorical or literal, but there is no explicit call for violence. Evidence: No direct incitement or encouragement of violence present.\n\n3. Vulgarity and/or Offensive Language: The word 'idiots' is an insult and offensive language, but it is not a slur or profanity. It is not a hate term per se, but it is derogatory. Evidence: 'idiots.'\n\nSummary: The post contains offensive language ('idiots') and references a group or place (#Paristan), but it does not clearly target a protected characteristic, nor does it call for violence or use hate slurs.",
      "annotation": 0,
      "confidence": 70,
      "guideline_improvement": "when content lacks explicit evidence of demeaning language, calls for violence, or offensive slurs targeting protected characteristics, despite potential ambiguity, sarcasm, indirect references, or coded language -> classify as 0 (no hate speech) with low confidence due to ambiguity"
    },
    {
      "text_to_annotate": "So...people wouldn't mind if I...",
      "uid": "ddaaf56b-f8de-4740-a1d0-f867c7fbc48f",
      "edge_case_id": 4.0,
      "pca_x": -0.34693699519244325,
      "pca_y": 0.04857231959254202,
      "raw_annotations": "{\n  \"analysis\": \"Guideline 1: Assaults on Human Dignity â€“ Not satisfied. The post does not mention or demean any individual or group based on protected characteristics. No evidence present. Guideline 2: Calls for Violence â€“ Not satisfied. There is no incitement or encouragement of violence in the text. No evidence present. Guideline 3: Vulgarity and/or Offensive Language â€“ Not satisfied. The post contains no profanity, slurs, or offensive language. No evidence present.\",\n  \"annotation\": \"-1\",\n  \"confidence\": 30,\n  \"new_edge_case\": true,\n  \"new_edge_case_rule\": \"When a post is incomplete or lacks sufficient context to determine intent or content regarding hate speech -> refuse to classify (-1)\"\n}",
      "analyses": "Guideline 1: Assaults on Human Dignity â€“ Not satisfied. The post does not mention or demean any individual or group based on protected characteristics. No evidence present. Guideline 2: Calls for Violence â€“ Not satisfied. There is no incitement or encouragement of violence in the text. No evidence present. Guideline 3: Vulgarity and/or Offensive Language â€“ Not satisfied. The post contains no profanity, slurs, or offensive language. No evidence present.",
      "annotation": -1,
      "confidence": 30,
      "guideline_improvement": "when content lacks sufficient information for evaluation (e.g., URLs, non-text media, ambiguous language, or insufficient context) -> refuse to classify (-1)"
    },
    {
      "text_to_annotate": "https://www.zerohedge.com/news/2018-08-27/english-town-31-muslims-charged-sex-crimes-against-kids-young-12  ",
      "uid": "b5f92d5f-5b64-45b5-887e-00cd7435ee3d",
      "edge_case_id": 1.0,
      "pca_x": 0.03497461480699318,
      "pca_y": -0.11229447003421103,
      "raw_annotations": "{\n  \"analysis\": \"Step-by-step evaluation of ALL guideline criteria with text evidence:\\n\\n1. Assaults on Human Dignity: The post is a URL linking to a news article with the headline 'English town: 31 Muslims charged sex crimes against kids young 12.' The headline explicitly identifies the alleged perpetrators by their religious affiliation ('Muslims'), which could be seen as associating a negative criminal act with a protected group. However, the post itself does not contain explicit demeaning or degrading language; it simply states a news headline. There is a risk of group-based negative association, but the post does not overtly demean or degrade.\\n\\n2. Calls for Violence: There is no language in the post that incites or encourages physical harm or violence against individuals or groups. The post is a headline and a link, with no call to action or incitement.\\n\\n3. Vulgarity and/or Offensive Language: The post does not contain profanity, slurs, or other offensive language. It uses formal language typical of news headlines.\\n\\nText evidence: The only text is the headline and the URL, which does not contain explicit hate speech elements per the guideline, though it does risk negative group association by specifying 'Muslims.'\",\n  \"annotation\": \"0\",\n  \"confidence\": 70,\n  \"new_edge_case\": true,\n  \"new_edge_case_rule\": \"When a post shares a news headline or link that associates a crime with a protected group without explicit demeaning language or calls for violence -> classify as 0 unless additional context or commentary is present\"\n}",
      "analyses": "Step-by-step evaluation of ALL guideline criteria with text evidence:\n\n1. Assaults on Human Dignity: The post is a URL linking to a news article with the headline 'English town: 31 Muslims charged sex crimes against kids young 12.' The headline explicitly identifies the alleged perpetrators by their religious affiliation ('Muslims'), which could be seen as associating a negative criminal act with a protected group. However, the post itself does not contain explicit demeaning or degrading language; it simply states a news headline. There is a risk of group-based negative association, but the post does not overtly demean or degrade.\n\n2. Calls for Violence: There is no language in the post that incites or encourages physical harm or violence against individuals or groups. The post is a headline and a link, with no call to action or incitement.\n\n3. Vulgarity and/or Offensive Language: The post does not contain profanity, slurs, or other offensive language. It uses formal language typical of news headlines.\n\nText evidence: The only text is the headline and the URL, which does not contain explicit hate speech elements per the guideline, though it does risk negative group association by specifying 'Muslims.'",
      "annotation": 0,
      "confidence": 70,
      "guideline_improvement": "when the post references protected groups but lacks explicit assaults on dignity, calls for violence, or vulgarity/offensive language directed at them -> classify as 0 (no hate speech)"
    },
    {
      "text_to_annotate": "https://www.huffingtonpost.com/entry/hurricane-mar... Thats a lot more DemonRat voters.",
      "uid": "c67ec4bd-4ea9-4f2a-9ecc-0c4d95cc991b",
      "edge_case_id": 0.0,
      "pca_x": 0.18602807395202653,
      "pca_y": -0.2540059066019592,
      "raw_annotations": "{\n  \"analysis\": \"1. Assaults on Human Dignity: Checking if the post demeans or degrades individuals or groups based on protected characteristics. The term 'DemonRat' is a derogatory play on 'Democrat,' intended to insult or demean members of the Democratic Party. However, political affiliation is not explicitly listed as a protected characteristic in the guideline (race, ethnicity, gender, religion, sexual orientation, or other protected characteristics). No evidence of attacks based on those protected characteristics is present. 2. Calls for Violence: Checking for incitement or encouragement of physical harm or violence. The post does not contain any language that incites or encourages violence. 3. Vulgarity and/or Offensive Language: Checking for profanity, slurs, or other offensive language. The term 'DemonRat' is a pejorative and offensive term directed at a political group, but it is not a traditional slur or profanity. It is, however, an offensive neologism.\",\n  \"annotation\": \"0\",\n  \"confidence\": 80,\n  \"new_edge_case\": true,\n  \"new_edge_case_rule\": \"When a post uses derogatory or offensive language targeting political affiliation (not a protected characteristic per guideline) but does not target protected characteristics, incite violence, or use traditional slurs/profanity -> classify as 0 (no hate speech)\"\n}",
      "analyses": "1. Assaults on Human Dignity: Checking if the post demeans or degrades individuals or groups based on protected characteristics. The term 'DemonRat' is a derogatory play on 'Democrat,' intended to insult or demean members of the Democratic Party. However, political affiliation is not explicitly listed as a protected characteristic in the guideline (race, ethnicity, gender, religion, sexual orientation, or other protected characteristics). No evidence of attacks based on those protected characteristics is present. 2. Calls for Violence: Checking for incitement or encouragement of physical harm or violence. The post does not contain any language that incites or encourages violence. 3. Vulgarity and/or Offensive Language: Checking for profanity, slurs, or other offensive language. The term 'DemonRat' is a pejorative and offensive term directed at a political group, but it is not a traditional slur or profanity. It is, however, an offensive neologism.",
      "annotation": 0,
      "confidence": 80,
      "guideline_improvement": "when the post targets non-protected groups, individuals, or characteristics (e.g., political groups, institutions, public figures) without explicit calls for violence or slurs targeting protected groups -> classify as 0 (no hate speech)"
    },
    {
      "text_to_annotate": "Epic comment thread on Mollie Tibbett's self-hating-but-now-ironic 'I hate White people' Twatter post (also brutal stuff on other posts where she hates on Trump and his policies against illegal immigration).https://twitter.com/Motibbs/status/940792919266680...",
      "uid": "147782c2-dd7a-44f5-800f-09b604efa8bf",
      "edge_case_id": 7.0,
      "pca_x": 0.11391511901858531,
      "pca_y": -0.07719175918967958,
      "raw_annotations": "{\n  \"analysis\": \"1. Assaults on Human Dignity: This criterion checks for demeaning or degrading language targeting protected characteristics (race, ethnicity, gender, etc.). The post references Mollie Tibbetts' (misspelled as 'Tibbett') 'I hate White people' post, describing it as 'self-hating-but-now-ironic.' The quoted phrase 'I hate White people' is a direct expression of hate based on race, but it is attributed to someone else (Mollie Tibbetts), not the author of this post. The author does not explicitly endorse or repeat the sentiment as their own, but highlights it and calls it 'ironic.' There is no direct evidence that the author is demeaning or degrading a group themselves, but the post does amplify and draw attention to a racially charged statement.\\n\\n2. Calls for Violence: This criterion checks for incitement or encouragement of physical harm. There is no evidence in the post of any call for violence or encouragement of harm against any individual or group. No language in the post suggests violence.\\n\\n3. Vulgarity and/or Offensive Language: This criterion checks for profanity, slurs, or other offensive language. The post uses the term 'Twatter' (a derogatory play on 'Twitter'), which is vulgar and offensive. The phrase 'brutal stuff' is vague but not inherently offensive. The post also references 'I hate White people,' which is an offensive statement, but again, it is attributed to someone else and not directly used by the author as their own statement.\\n\\nSummary: The post does not directly express hate speech from the author, but it does amplify and draw attention to a racially charged and offensive statement made by someone else. The use of 'Twatter' is vulgar. However, according to the guidelines, hate speech requires the post itself to contain demeaning, violent, or offensive language directed at protected groups. The post is borderline, as it amplifies hate speech but does not directly express it.\",\n  \"annotation\": \"0\",\n  \"confidence\": 70,\n  \"new_edge_case\": true,\n  \"new_edge_case_rule\": \"When a post amplifies or references hate speech made by others without explicit endorsement or repetition as the author's own statement, and does not directly demean, incite violence, or use slurs against protected groups, but uses vulgar language -> classify as 0 (no hate speech), but flag for review if amplification is significant.\"\n}",
      "analyses": "1. Assaults on Human Dignity: This criterion checks for demeaning or degrading language targeting protected characteristics (race, ethnicity, gender, etc.). The post references Mollie Tibbetts' (misspelled as 'Tibbett') 'I hate White people' post, describing it as 'self-hating-but-now-ironic.' The quoted phrase 'I hate White people' is a direct expression of hate based on race, but it is attributed to someone else (Mollie Tibbetts), not the author of this post. The author does not explicitly endorse or repeat the sentiment as their own, but highlights it and calls it 'ironic.' There is no direct evidence that the author is demeaning or degrading a group themselves, but the post does amplify and draw attention to a racially charged statement.\n\n2. Calls for Violence: This criterion checks for incitement or encouragement of physical harm. There is no evidence in the post of any call for violence or encouragement of harm against any individual or group. No language in the post suggests violence.\n\n3. Vulgarity and/or Offensive Language: This criterion checks for profanity, slurs, or other offensive language. The post uses the term 'Twatter' (a derogatory play on 'Twitter'), which is vulgar and offensive. The phrase 'brutal stuff' is vague but not inherently offensive. The post also references 'I hate White people,' which is an offensive statement, but again, it is attributed to someone else and not directly used by the author as their own statement.\n\nSummary: The post does not directly express hate speech from the author, but it does amplify and draw attention to a racially charged and offensive statement made by someone else. The use of 'Twatter' is vulgar. However, according to the guidelines, hate speech requires the post itself to contain demeaning, violent, or offensive language directed at protected groups. The post is borderline, as it amplifies hate speech but does not directly express it.",
      "annotation": 0,
      "confidence": 70,
      "guideline_improvement": "when content reports offensive material or uses insensitive language without direct targeting of protected groups -> classify as no hate speech (0) but flag for review/insensitivity"
    },
    {
      "text_to_annotate": "Because they're not a news outlet, they're producing war propaganda for the white genocide.",
      "uid": "cbacd494-1fe7-4504-8e3d-853c9f348550",
      "edge_case_id": 6.0,
      "pca_x": 0.0058107353176027055,
      "pca_y": -0.10323940812446393,
      "raw_annotations": "{\n  \"analysis\": \"1. Assaults on Human Dignity: Checking if the post demeans or degrades individuals or groups based on protected characteristics. The phrase 'war propaganda for the white genocide' references a conspiracy theory often used in hate speech contexts to suggest that white people are being systematically eliminated. While the post does not directly insult or demean a group, it invokes a narrative that is commonly associated with racist ideology. However, the post itself does not explicitly attack or degrade any group. Guideline component: Not clearly satisfied, but contextually suggestive. Evidence: 'war propaganda for the white genocide.'\\n\\n2. Calls for Violence: Checking if the post incites or encourages physical harm or violence. There is no explicit or implicit call for violence in the post. Guideline component: Not satisfied. Evidence: No language inciting violence.\\n\\n3. Vulgarity and/or Offensive Language: Checking for profanity, slurs, or offensive language. The post does not contain profanity or slurs. The term 'white genocide' is offensive in some contexts due to its association with hate speech, but in this post, it is used as part of a conspiracy theory claim rather than as a direct slur. Guideline component: Partially suggestive, but not explicit. Evidence: 'white genocide.'\",\n  \"annotation\": \"1\",\n  \"confidence\": 80,\n  \"new_edge_case\": true,\n  \"new_edge_case_rule\": \"When a post references hate-based conspiracy theories (e.g., 'white genocide') without explicit slurs or direct demeaning language, but contextually invokes hate speech narratives -> classify as hate speech (1)\"\n}",
      "analyses": "1. Assaults on Human Dignity: Checking if the post demeans or degrades individuals or groups based on protected characteristics. The phrase 'war propaganda for the white genocide' references a conspiracy theory often used in hate speech contexts to suggest that white people are being systematically eliminated. While the post does not directly insult or demean a group, it invokes a narrative that is commonly associated with racist ideology. However, the post itself does not explicitly attack or degrade any group. Guideline component: Not clearly satisfied, but contextually suggestive. Evidence: 'war propaganda for the white genocide.'\n\n2. Calls for Violence: Checking if the post incites or encourages physical harm or violence. There is no explicit or implicit call for violence in the post. Guideline component: Not satisfied. Evidence: No language inciting violence.\n\n3. Vulgarity and/or Offensive Language: Checking for profanity, slurs, or offensive language. The post does not contain profanity or slurs. The term 'white genocide' is offensive in some contexts due to its association with hate speech, but in this post, it is used as part of a conspiracy theory claim rather than as a direct slur. Guideline component: Partially suggestive, but not explicit. Evidence: 'white genocide.'",
      "annotation": 1,
      "confidence": 80,
      "guideline_improvement": "when a post dehumanizes protected groups by invalidating identities or trivializing atrocities through symbolism/narratives -> classify as hate speech (1)"
    },
    {
      "text_to_annotate": "#Europe #Germany #Rape #Islam #Muslims #Migrants #MuslimMigrants #Immigration #IslamicImmigration ",
      "uid": "0b930a36-73e9-487f-b81c-c7cc2491ecb8",
      "edge_case_id": 4.0,
      "pca_x": -0.2795895341332602,
      "pca_y": -0.12920218265984193,
      "raw_annotations": "{\n  \"analysis\": \"Step-by-step evaluation of ALL guideline criteria with text evidence:\\n\\n1. Assaults on Human Dignity: Checking if the post demeans or degrades individuals or groups based on protected characteristics. The post consists entirely of hashtags, many of which reference groups (e.g., #Islam, #Muslims, #MuslimMigrants, #Migrants) and topics (#Rape, #Immigration, #IslamicImmigration). The juxtaposition of #Rape with #Islam, #Muslims, and #MuslimMigrants could be interpreted as associating these groups with criminal behavior (rape), which may be seen as demeaning or degrading. However, there is no explicit statement or direct insult; the association is implied through hashtag co-occurrence.\\n\\n2. Calls for Violence: Checking for incitement or encouragement of physical harm or violence. There is no explicit or implicit call for violence in the hashtags provided. No language encourages harm or violence against any group.\\n\\n3. Vulgarity and/or Offensive Language: Checking for profanity, slurs, or other offensive language. The hashtags themselves do not contain profanity or slurs. However, the combination of #Rape with group identifiers could be considered offensive or inflammatory, but not vulgar in the sense of explicit language.\\n\\nSummary: The post does not contain explicit hate speech (no direct demeaning language, no calls for violence, no slurs or profanity). However, the co-occurrence of #Rape with group identifiers (#Islam, #Muslims, #MuslimMigrants) may be interpreted as an attempt to associate these groups with criminality, which could be seen as an assault on human dignity through implication rather than direct statement. The guidelines do not specify how to handle implied associations via hashtags alone, making this an ambiguous case.\",\n  \"annotation\": \"-1\",\n  \"confidence\": 60,\n  \"new_edge_case\": true,\n  \"new_edge_case_rule\": \"When a post consists solely of hashtags that, through their co-occurrence, imply a negative association with a protected group but contain no explicit statements, slurs, or calls for violence -> refuse to classify (-1)\"\n}",
      "analyses": "Step-by-step evaluation of ALL guideline criteria with text evidence:\n\n1. Assaults on Human Dignity: Checking if the post demeans or degrades individuals or groups based on protected characteristics. The post consists entirely of hashtags, many of which reference groups (e.g., #Islam, #Muslims, #MuslimMigrants, #Migrants) and topics (#Rape, #Immigration, #IslamicImmigration). The juxtaposition of #Rape with #Islam, #Muslims, and #MuslimMigrants could be interpreted as associating these groups with criminal behavior (rape), which may be seen as demeaning or degrading. However, there is no explicit statement or direct insult; the association is implied through hashtag co-occurrence.\n\n2. Calls for Violence: Checking for incitement or encouragement of physical harm or violence. There is no explicit or implicit call for violence in the hashtags provided. No language encourages harm or violence against any group.\n\n3. Vulgarity and/or Offensive Language: Checking for profanity, slurs, or other offensive language. The hashtags themselves do not contain profanity or slurs. However, the combination of #Rape with group identifiers could be considered offensive or inflammatory, but not vulgar in the sense of explicit language.\n\nSummary: The post does not contain explicit hate speech (no direct demeaning language, no calls for violence, no slurs or profanity). However, the co-occurrence of #Rape with group identifiers (#Islam, #Muslims, #MuslimMigrants) may be interpreted as an attempt to associate these groups with criminality, which could be seen as an assault on human dignity through implication rather than direct statement. The guidelines do not specify how to handle implied associations via hashtags alone, making this an ambiguous case.",
      "annotation": -1,
      "confidence": 60,
      "guideline_improvement": "when content lacks sufficient information for evaluation (e.g., URLs, non-text media, ambiguous language, or insufficient context) -> refuse to classify (-1)"
    },
    {
      "text_to_annotate": "bill clinton is a rapist",
      "uid": "a83b79fb-0036-41a4-b1fe-256b4038729b",
      "edge_case_id": 0.0,
      "pca_x": 0.15989572891690046,
      "pca_y": -0.18618988249041302,
      "raw_annotations": "{\n  \"analysis\": \"1. Assaults on Human Dignity: This criterion checks if the post demeans or degrades individuals or groups based on protected characteristics (race, ethnicity, gender, religion, sexual orientation, etc.). The post states 'bill clinton is a rapist.' This is a serious accusation against a specific individual, but it is not based on any protected characteristic. Therefore, this criterion is NOT satisfied. 2. Calls for Violence: This criterion checks if the post incites or encourages physical harm or violence against individuals or groups. The post does not contain any language that calls for or encourages violence. Therefore, this criterion is NOT satisfied. 3. Vulgarity and/or Offensive Language: This criterion checks for profanity, slurs, or other offensive language. The word 'rapist' is a highly offensive and serious accusation, but it is not a slur or profanity in itself; it is a criminal accusation. The post does not use vulgar language or slurs, but the accusation is offensive in nature. However, the guideline specifies 'profanity, slurs, or other offensive language that may or may not be directed at individuals or groups.' The term 'rapist' is offensive when used as an accusation, but it is not a slur or profanity. Therefore, this criterion is only partially satisfied, as the offensiveness is context-dependent and not clearly defined in the guideline.\",\n  \"annotation\": \"0\",\n  \"confidence\": 70,\n  \"new_edge_case\": true,\n  \"new_edge_case_rule\": \"When a post makes a highly offensive criminal accusation against an individual that is not based on protected characteristics and does not use slurs or profanity -> classify as 0 (no hate speech)\"\n}",
      "analyses": "1. Assaults on Human Dignity: This criterion checks if the post demeans or degrades individuals or groups based on protected characteristics (race, ethnicity, gender, religion, sexual orientation, etc.). The post states 'bill clinton is a rapist.' This is a serious accusation against a specific individual, but it is not based on any protected characteristic. Therefore, this criterion is NOT satisfied. 2. Calls for Violence: This criterion checks if the post incites or encourages physical harm or violence against individuals or groups. The post does not contain any language that calls for or encourages violence. Therefore, this criterion is NOT satisfied. 3. Vulgarity and/or Offensive Language: This criterion checks for profanity, slurs, or other offensive language. The word 'rapist' is a highly offensive and serious accusation, but it is not a slur or profanity in itself; it is a criminal accusation. The post does not use vulgar language or slurs, but the accusation is offensive in nature. However, the guideline specifies 'profanity, slurs, or other offensive language that may or may not be directed at individuals or groups.' The term 'rapist' is offensive when used as an accusation, but it is not a slur or profanity. Therefore, this criterion is only partially satisfied, as the offensiveness is context-dependent and not clearly defined in the guideline.",
      "annotation": 0,
      "confidence": 70,
      "guideline_improvement": "when the post targets non-protected groups, individuals, or characteristics (e.g., political groups, institutions, public figures) without explicit calls for violence or slurs targeting protected groups -> classify as 0 (no hate speech)"
    },
    {
      "text_to_annotate": "Today is â€œInternational Vulture Awareness Dayâ€ Who knew ? ðŸ¤·ðŸ¼â€â™‚ï¸ There are some left wing carcuses out there....just sayin !",
      "uid": "0d0f2e38-3cd6-44fe-a72b-9745ddfab965",
      "edge_case_id": 0.0,
      "pca_x": 0.20665103537364116,
      "pca_y": -0.22021064635411416,
      "raw_annotations": "{\n  \"analysis\": \"1. Assaults on Human Dignity: This criterion checks for demeaning or degrading language based on protected characteristics (race, ethnicity, gender, religion, sexual orientation, etc.). The post uses the phrase 'left wing carcuses,' which is a play on words combining 'left wing' (a political orientation) and 'carcasses' (dead bodies). While this is derogatory toward people with left-wing political views, political orientation is not explicitly listed as a protected characteristic in the guideline. No evidence of attacks based on race, ethnicity, gender, religion, or sexual orientation is present. \\n\\n2. Calls for Violence: This criterion checks for incitement or encouragement of physical harm or violence. The post does not explicitly or implicitly call for violence against any group or individual. The phrase 'carcuses' is metaphorical and not a direct call for harm. \\n\\n3. Vulgarity and/or Offensive Language: This criterion checks for profanity, slurs, or other offensive language. The term 'carcuses' (carcasses) is derogatory and dehumanizing, but it is not a recognized slur or profanity. The tone is mocking and dismissive, but not overtly vulgar. \\n\\nText evidence: 'There are some left wing carcuses out there....just sayin !' is the only potentially offensive phrase, but it targets political ideology, not a protected characteristic per the guideline.\",\n  \"annotation\": \"0\",\n  \"confidence\": 80,\n  \"new_edge_case\": true,\n  \"new_edge_case_rule\": \"When derogatory or dehumanizing language targets political ideology (not listed as a protected characteristic) without explicit calls for violence or use of slurs -> classify as 0 (no hate speech)\"\n}",
      "analyses": "1. Assaults on Human Dignity: This criterion checks for demeaning or degrading language based on protected characteristics (race, ethnicity, gender, religion, sexual orientation, etc.). The post uses the phrase 'left wing carcuses,' which is a play on words combining 'left wing' (a political orientation) and 'carcasses' (dead bodies). While this is derogatory toward people with left-wing political views, political orientation is not explicitly listed as a protected characteristic in the guideline. No evidence of attacks based on race, ethnicity, gender, religion, or sexual orientation is present. \n\n2. Calls for Violence: This criterion checks for incitement or encouragement of physical harm or violence. The post does not explicitly or implicitly call for violence against any group or individual. The phrase 'carcuses' is metaphorical and not a direct call for harm. \n\n3. Vulgarity and/or Offensive Language: This criterion checks for profanity, slurs, or other offensive language. The term 'carcuses' (carcasses) is derogatory and dehumanizing, but it is not a recognized slur or profanity. The tone is mocking and dismissive, but not overtly vulgar. \n\nText evidence: 'There are some left wing carcuses out there....just sayin !' is the only potentially offensive phrase, but it targets political ideology, not a protected characteristic per the guideline.",
      "annotation": 0,
      "confidence": 80,
      "guideline_improvement": "when the post targets non-protected groups, individuals, or characteristics (e.g., political groups, institutions, public figures) without explicit calls for violence or slurs targeting protected groups -> classify as 0 (no hate speech)"
    },
    {
      "text_to_annotate": "Online now only those who are horny in SarahÂ Palin.",
      "uid": "86a8e5d7-c9b7-4900-94ab-05517e476079",
      "edge_case_id": 0.0,
      "pca_x": 0.08588243329677231,
      "pca_y": 0.055771470427244646,
      "raw_annotations": "{\n  \"analysis\": \"1. Assaults on Human Dignity: Checking if the post demeans or degrades individuals or groups based on protected characteristics (race, ethnicity, gender, religion, sexual orientation, etc.). The post references 'Sarah Palin' but does not explicitly demean or degrade her or any group based on protected characteristics. No evidence found. \\n2. Calls for Violence: Checking for incitement or encouragement of physical harm or violence. The post does not contain any language that incites or encourages violence. No evidence found. \\n3. Vulgarity and/or Offensive Language: Checking for profanity, slurs, or other offensive language. The phrase 'horny in Sarah Palin' is sexually suggestive and could be considered vulgar or offensive, especially as it references a public figure in a sexualized manner. However, it does not use explicit profanity or slurs, and the offensiveness is context-dependent.\",\n  \"annotation\": \"0\",\n  \"confidence\": 70,\n  \"new_edge_case\": true,\n  \"new_edge_case_rule\": \"When a post contains sexually suggestive or potentially offensive language about a public figure but does not explicitly demean based on protected characteristics or use slurs/profanity -> classify as 0 (no hate speech), but flag for review if context is ambiguous\"\n}",
      "analyses": "1. Assaults on Human Dignity: Checking if the post demeans or degrades individuals or groups based on protected characteristics (race, ethnicity, gender, religion, sexual orientation, etc.). The post references 'Sarah Palin' but does not explicitly demean or degrade her or any group based on protected characteristics. No evidence found. \n2. Calls for Violence: Checking for incitement or encouragement of physical harm or violence. The post does not contain any language that incites or encourages violence. No evidence found. \n3. Vulgarity and/or Offensive Language: Checking for profanity, slurs, or other offensive language. The phrase 'horny in Sarah Palin' is sexually suggestive and could be considered vulgar or offensive, especially as it references a public figure in a sexualized manner. However, it does not use explicit profanity or slurs, and the offensiveness is context-dependent.",
      "annotation": 0,
      "confidence": 70,
      "guideline_improvement": "when the post targets non-protected groups, individuals, or characteristics (e.g., political groups, institutions, public figures) without explicit calls for violence or slurs targeting protected groups -> classify as 0 (no hate speech)"
    }
  ]
}